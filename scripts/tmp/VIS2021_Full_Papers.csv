Source,Paper ID,Title,Abstract,Keywords,Author 1 - first,Author 1 - last,Author 2 - first,Author 2 - last,Author 3 - first,Author 3 - last,Author 4 - first,Author 4 - last,Author 5 - first,Author 5 - last,Author 6 - first,Author 6 - last,Author 7 - first,Author 7 - last,Author 8 - first,Author 8 - last,Author 9 - first,Author 9 - last,Author 10 - first,Author 10 - last,Author 11 - first,Author 11 - last,Author 12 - first,Author 12 - last,Author 13 - first,Author 13 - last,ACM Author Affiliations,"ACM Author Emails, excluding contact email"
Representations & Interaction,1008,Kori: Interactive Synthesis of Text and Charts in Data Documents,"Charts go hand in hand with text to communicate complex data and are widely adopted in news articles, online blogs, and academic papers. They provide graphical summaries of the data, while text explains the message and context. However, synthesizing information across text and charts is difficult; it requires readers to frequently shift their attention. We investigated ways to support the tight coupling of text and charts in data documents. To understand their interplay, we analyzed the design space of such references through news articles and scientific papers. Informed by the analysis, we developed a mixed-initiative interface enabling users to construct interactive references between text and charts. It leverages natural language processing to automatically suggest references as well as allows users to manually construct other references effortlessly. A user study complemented with algorithmic evaluation of the system suggests that the interface provides an effective way to compose interactive data documents.","Tabular Data ; Interaction Design ; Communication/Presentation, Storytelling ; General Public ; Mixed Initiative Human-Machine Analysis ; Charts, Diagrams, and Plots",Shahid,Latif,Zheng,Zhou,Yoon,Kim,Fabian,Beck,Nam Wook,Kim,,,,,,,,,,,,,,,,,Shahid Latif: University of Duisburg-Essen; Zheng Zhou: Boston College; Yoon Kim: MIT; Fabian Beck: University of Duisburg-Essen; Nam Wook Kim: Boston College,zhoupt@bc.edu; yoonkim@mit.edu; fabian.beck@paluno.uni-due.de; nam.wook.kim@bc.edu
Representations & Interaction,1010,Improving Visualization Interpretation Using Counterfactuals,"Complex, high-dimensional data is used in a wide range of domains to explore problems and make decisions. Analysis of high-dimensional data, however, is vulnerable to the hidden influence of confounding variables, especially as users apply ad hoc filtering operations to visualize only specific subsets of an entire dataset. Thus, visual data-driven analysis can mislead users and encourage mistaken assumptions about causality or the strength of relationships between features. This work introduces a novel visual approach designed to reveal the presence of confounding variables via counterfactual possibilities during visual data analysis. It is implemented in CoFact, an interactive visualization prototype that determines and visualizes counterfactual subsets to better support user exploration of feature relationships. Using publicly available datasets, we conducted a controlled user study to demonstrate the effectiveness of our approach; the results indicate that users exposed to counterfactual visualizations formed more careful judgments about feature-to-outcome relationships.","visualization, counterfactuals, human-computer interaction, human-centered computing, empirical study",Smiti,Kaul,David,Borland,Nan,Cao,David,Gotz,,,,,,,,,,,,,,,,,,,Smiti Kaul: University of North Carolina at Chapel Hill; David Borland: UNC-Chapel Hill; Nan Cao: Tongji College of Design and Innovation; David Gotz: University of North Carolina,borland@renci.org; nan.cao@gmail.com; gotz@unc.edu
Data Transformations,1011,A Domain-Oblivious Approach for Learning Concise Representations of Filtered Topological Spaces for Clustering,"Persistence diagrams have been widely used to quantify the underlying features of filtered topological spaces in data visualization. In many applications, computing distances between diagrams is essential; however, computing these distances has been challenging due to the computational cost. In this paper, we propose a persistence diagram hashing framework that learns a binary code representation of persistence diagrams, which allows for fast computation of distances. This framework is built upon a generative adversarial network (GAN) with a diagram distance loss function to steer the learning process. Instead of using standard representations, we hash diagrams into binary codes, which have natural advantages in large-scale tasks. The training of this model is domain-oblivious in that it can be computed purely from synthetic, randomly created diagrams. As a consequence, our proposed method is directly applicable to various datasets without the need for retraining the model. These binary codes, when compared using fast Hamming distance, better maintain topological similarity properties between datasets than other vectorized representations. To evaluate this method, we apply our framework to the problem of diagram clustering and we compare the quality and performance of our approach to the state-of-the-art.  In addition, we show the scalability of our approach on a dataset with 10k persistence diagrams, which is not possible with current techniques. Moreover, our experimental results demonstrate that our method is significantly faster with the potential of less memory usage, while retaining comparable or better quality comparisons.","Topological data analysis, Persistence diagrams, Persistence diagram distances, Learned hashing, Clustering.",Yu,Qin,Brittany Terese,Fasy,Carola,Wenk,Brian,Summa,,,,,,,,,,,,,,,,,,,Yu Qin: Tulane University; Brittany Terese Fasy: Montana State University; Carola Wenk: Tulane University; Brian Summa: Tulane University,yqin2@tulane.edu; brittany.fasy@montana.edu; cwenk@tulane.edu
Analytics & Decisions,1017,Lumos: Increasing Awareness of Analytic Behavior during Visual Data Analysis,"Visual data analysis tools provide people with the agency and flexibility to explore data using a variety of interactive functionality. However, this flexibility may introduce potential consequences in situations where users unknowingly overemphasize or underemphasize specific subsets of the data or attribute space they are analyzing. For example, users may overemphasize specific attributes and/or their values (e.g., Gender is always encoded on the X axis), underemphasize others (e.g., Religion is never encoded), ignore a subset of the data (e.g., older people are filtered out), etc. In response, we present Lumos, a visual data analysis tool that captures and shows the interaction history with data to increase awareness of such analytic behaviors. Using in-situ (at the place of interaction) and ex-situ (in an external view) visualization techniques, Lumos provides real-time feedback to users for them to reflect on their activities. For example, Lumos highlights datapoints that have been previously examined in the same visualization (in-situ) and also overlays them on the underlying data distribution (i.e., baseline distribution) in a separate visualization (ex-situ). Through a user study with 24 participants, we investigate how Lumos helps users' data exploration and decision-making processes. We found that Lumos increases users' awareness of visual data analysis practices in real-time, promoting reflection upon and acknowledgement of their intentions and potentially influencing subsequent interactions.","visual data analysis, interaction traces, analytic provenance, awareness, human bias",Arpit,Narechania,Adam,Coscia,Emily,Wall,Alex,Endert,,,,,,,,,,,,,,,,,,,Arpit Narechania: Georgia Institute of Technology; Adam J Coscia: Georgia Institute of Technology; Emily Wall: Northwestern University; Alex Endert: Georgia Institute of Technology,acoscia6@gatech.edu; emily.wall@northwestern.edu; endert@gatech.edu
Data Transformations,1020,Measuring and Explaining the Inter-Cluster Reliability of Multidimensional Projections,"We propose Steadiness and Cohesiveness, two novel metrics to measure the inter-cluster reliability of multidimensional projection (MDP), specifically how well the inter-cluster structures are preserved between the original high-dimensional space and the low-dimensional projection space. Measuring inter-cluster reliability is crucial as it directly affects how well inter-cluster tasks (e.g., identifying cluster relationships in the original space from a projected view) can be conducted; however, despite the importance of inter-cluster tasks, we found that previous metrics, such as Trustworthiness and Continuity, fail to measure inter-cluster reliability. Our metrics consider two aspects of the inter-cluster reliability: Steadiness measures the extent to which clusters in the projected space form clusters in the original space, and Cohesiveness measures the opposite. They extract random clusters with arbitrary shapes and positions in one space and evaluate how much the clusters are stretched or dispersed in the other space. Furthermore, our metrics can quantify pointwise distortions, allowing for the visualization of inter-cluster reliability in a projection, which we call a reliability map. Through quantitative experiments, we verify that our metrics precisely capture the distortions that harm inter-cluster reliability while previous metrics have difficulty capturing the distortions. A case study also demonstrates that our metrics and the reliability map 1) support users in selecting the proper projection techniques or hyperparameters and 2) prevent misinterpretation while performing inter-cluster tasks, thus allow an adequate identification of inter-cluster structure.","Multidimensional projections, MDP distortions, Inter-cluster tasks, Inter-cluster reliability, Distortion metrics",Hyeon,Jeon,Hyung-Kwon,Ko,Jaemin,Jo,Youngtaek,Kim,Jinwook,Seo,,,,,,,,,,,,,,,,,Hyeon Jeon: Seoul National University; Hyung-Kwon Ko: Seoul National University; Jaemin Jo: Sungkyunkwan University; Youngtaek Kim: Seoul National University.; Jinwook Seo: Seoul National University,hkko@hcil.snu.ac.kr; jmjo@skku.edu; ytaek.kim@hcil.snu.ac.kr; jseo@snu.ac.kr
Theoretical & Empirical,1022,"Exploring the personal informatics analysis gap: ""There's a lot of bacon""","Personal informatics research supports people in tracking personal data for the purposes of self-reflection and gaining self-knowledge. This field, however, has predominantly focused on the data collection and insight-generation elements of self-tracking, with less attention paid to flexible data analysis. As a result, this inattention has lead to inflexible analytic pipelines that do not reflect or support the diverse ways people want to engage their data. This paper contributes a review of personal informatics and visualization research literature to expose a gap in our knowledge for designing flexible tools that assist people with engaging and analyzing personal data in personal contexts, which we call the personal informatics analysis gap. We explore this gap through a multi-stage longitudinal study on how asthmatics engage personal air quality data, and we report how participants: are motivated by broad and diverse goals; exhibited patterns in the way they explored their data; engaged with their data in playful ways; discovered new insights through serendipitous exploration; and were reluctant to use analysis tools on their own. These results present new opportunities for visual analysis research and suggest the need for fundamental shifts in how and what we design for supporting analysis of personal data.","Personal visualization, Personal visual analytics, Personal Informatics, Interview methods",Jimmy,Moore,Pascal,Goffin,Jason,Wiese,Miriah,Meyer,,,,,,,,,,,,,,,,,,,Jimmy Moore: University of Utah; Pascal Goffin: Asvito Digital AG; Jason Wiese: University of Utah; Miriah Meyer: University of Utah,ppjgoffin@gmail.com; wiese@cs.utah.edu; miriah@cs.utah.edu
Theoretical & Empirical,1028,Effect of uncertainty visualizations on myopic loss aversion and equity premium puzzle in retirement investment decisions,"For many households, investing for retirement is one of the most significant decisions and is fraught with uncertainty. In a classic study in behavioral economics, Benartzi and Thaler (1999) found evidence using bar charts that investors exhibit myopic loss aversion in retirement decisions: Investors overly focus on the potential for short-term losses, leading them to invest less in riskier assets and miss out on higher long-term returns. Recently, advances in uncertainty visualizations have shown improvements in decision-making under uncertainty in a variety of tasks. In this paper, we conduct a controlled and incentivized crowdsourced experiment replicating Benartzi and Thaler (1999) and extending it to measure the effect of different uncertainty representations on myopic loss aversion. Consistent with the original study, we find evidence of myopic loss aversion with bar charts and find that participants make better investment decisions with longer evaluation periods. We also find that common uncertainty representations such as interval plots and bar charts achieve the highest mean expected returns while other uncertainty visualizations lead to poorer long-term performance and strong effects on the equity premium. Qualitative feedback further suggests that different uncertainty representations lead to visual reasoning heuristics that can either mitigate or encourage a focus on potential short-term losses. We discuss implications of our results on using uncertainty visualizations for retirement decisions in practice and possible extensions for future work.","Uncertainty visualizations, myopic loss aversion, retirement investing, equity premium puzzle",Ryan,Wesslen,Alireza,Karduni,Doug,Markant,Wenwen,Dou,,,,,,,,,,,,,,,,,,,Ryan Wesslen: UNC Charlotte; Alireza Karduni: UNC Charlotte; Doug Markant: University of North Carolina at Charlotte; Wenwen Dou: UNC Charlotte,alireza.karduni@northwestern.edu; dmarkant@uncc.edu; wdou1@uncc.edu
Data Transformations,1035,MultiVision: Designing Analytical Dashboards with Deep Learning Based Recommendation,"We contribute a deep-learning-based method that assists in designing analytical dashboards for analyzing a data table.
Given a data table, data workers usually need to experience a tedious and time-consuming process to select meaningful combinations of data columns for creating charts. This process is further complicated by the needs of creating dashboards composed of multiple views that unveil different perspectives of data. Existing automated approaches for recommending multiple-view visualizations mainly build on manually crafted design rules, producing sub-optimal or irrelevant suggestions. To address this gap, we present a deep learning approach for selecting data columns and recommending multiple charts. More importantly, we integrate the deep learning models into a mixed-initiative system. Our model could make recommendations given optional user-input selections of data columns. The model, in turn, learns from provenance data of authoring logs in an offline manner. We compare our deep learning model with existing methods for visualization recommendation and conduct a user study to evaluate the usefulness of the system.","Visualization Recommendation, Deep Learning, Multiple-View, Dashboard, Mixed-Initiative, Visualization Provenance",Aoyu,Wu,Yun,Wang,Mengyu,Zhou,Xinyi,He,Haidong,Zhang,Huamin,Qu,Dongmei,Zhang,,,,,,,,,,,,,Aoyu Wu: Hong Kong University of Science and Technology; Yun Wang: Microsoft Research Asia; Mengyu Zhou: Microsoft Research; Xinyi He: Microsoft Research; Haidong Zhang: Microsoft Research Asia; Huamin Qu: The Hong Kong University of Science and Technology; Dongmei Zhang: Microsoft Research Asia,wangyun@microsoft.com; mezho@microsoft.com; hxyhxy@stu.xjtu.edu.cn; haizhang@microsoft.com; huamin@cse.ust.hk; dongmeiz@microsoft.com
Applications,1038,TIVEE: Visual Exploration and Explanation of Badminton Tactics in Immersive Visualizations,"Tactic analysis is a major issue in badminton as the effective usage of tactics is the key to win. The tactic in badminton is defined as a sequence of consecutive strokes. Most existing methods use statistical models to find sequential patterns of strokes and apply 2D visualizations such as glyphs and statistical charts to explore and analyze the discovered patterns. However, in badminton, spatial information like the shuttle trajectory, which is inherently 3D, is the core of a tactic. The lack of sufficient spatial awareness in 2D visualizations largely limited the tactic analysis of badminton. In this work, we collaborate with domain experts to study the tactic analysis of badminton in a 3D environment and propose an immersive visual analytics system, TIVEE, to assist users in exploring and explaining badminton tactics from multi-levels. Users can first explore various tactics from the third-person perspective using an unfolded visual presentation of stroke sequences. By selecting a tactic of interest, users can turn to the first-person perspective to perceive the detailed kinematic characteristics and explain its effects on the game result. The effectiveness and usefulness of TIVEE are demonstrated by case studies and an expert interview.","Tactic analysis, stroke sequence visualization, immersive visualization",Xiangtong,Chu,Xiao,Xie,Shuainan,Ye,Haolin,Lu,Hongguang,Xiao,Zeqing,Yuan,Zhutian,Chen,Hui,Zhang,Yingcai,Wu,,,,,,,,,Xiangtong Chu: Zhejiang University; Xiao Xie: Zhejiang University; Shuainan Ye: Zhejiang University; Haolin Lu: Zhejiang University; Hongguang Xiao: Zhejiang University; Zeqing Yuan: Zhejiang University; Zhutian Chen: University of California San Diego; Hui Zhang: Zhejiang University; Yingcai Wu: Zhejiang University,xxie@zju.edu.cn; sn_ye@outlook.com; suikasibyl@gmail.com; ip649302817@outlook.com; 3200105867@zju.edu.cn; zhutian@ucsd.edu; zhang_hui@zju.edu.cn; ycwu@zju.edu.cn
Data Transformations,1055,DDLVis: Real-time Visual Query of Spatiotemporal Data Distribution via Density Dictionary Learning,"Visual query of spatiotemporal data is becoming an increasingly important function in visual analytics applications. Various works have been presented for querying large spatiotemporal data in real time. However, the real-time query of spatiotemporal data distribution is still an open challenge. As spatiotemporal data become larger, methods of aggregation, storage and querying become critical. We propose a new visual query system that creates a low-memory storage component and provides real-time visual interactions of spatiotemporal data. We first present a peak-based kernel density estimation method to produce the data distribution for the spatiotemporal data. Then a novel density dictionary learning approach is proposed to compress temporal density maps and accelerate the query calculation. Moreover, various intuitive query interactions are presented to interactively gain patterns. The experimental results obtained on three datasets demonstrate that the presented system offers an effective query for visual analytics of spatiotemporal data.","Visual query, information visualization, spatiotemporal data, data compression, interaction, density map",Chenhui,Li,George,Baciu,Yunzhe,WANG,Junjie,Chen,Changbo,Wang,,,,,,,,,,,,,,,,,Chenhui Li: East China Normal University; George Baciu: The Hong Kong Polytechnic University; Yunzhe WANG: Suzhou University of Science and Technology; Junjie Chen: East China Normal University; Changbo Wang: East China Normal University,csgeorge@polyu.edu.hk; yunzhew1991@gmail.com; fleetingkl@outlook.com; cbwang@sei.ecnu.edu.cn
Representations & Interaction,1064,Generative Design Inspiration for Glyphs with Diatoms,"We introduce Diatoms, a technique that generates design inspiration for glyphs by sampling from palettes of mark shapes, encoding channels, and glyph scaffold shapes. Diatoms allows for a degree of randomness while respecting constraints imposed by columns in a data table: their data types and domains as well as semantic associations between columns as specified by the designer. We pair this generative design process with two forms of interactive design externalization that enable comparison and critique of the design alternatives. First, we incorporate a familiar small multiples configuration in which every data point is drawn according to a single glyph design, coupled with the ability to page between alternative glyph designs. Second, we propose a small permutables design gallery, in which a single data point is drawn according to each alternative glyph design, coupled with the ability to page between data points. We demonstrate an implementation of our technique as an extension to Tableau featuring three example palettes, and to better understand how Diatoms could fit into existing design workflows, we conducted interviews and chauffeured demos with 12 designers. Finally, we reflect on our process and the designers’ reactions, discussing the potential of our technique in the context of visualization authoring systems. Ultimately, our approach to glyph design and comparison can kickstart and inspire visualization design, allowing for the serendipitous discovery of shape and channel combinations that would have otherwise been overlooked.","Glyphs, multidimensional data, generative design, communicative visualization, small multiples, qualitative evaluation.",Matthew,Brehmer,Robert,Kosara,Carmen,Hull,,,,,,,,,,,,,,,,,,,,,Matthew Brehmer: Tableau Research; Robert Kosara: Tableau Research; Carmen Hull: University of Calgary,rkosara@tableau.com; carmen.hull@ucalgary.ca
Theoretical & Empirical,1065,From Jam Session to Concert Hall: Synchronous Communication and Collaboration Around Data in Organizations,"Prior research on communicating with visualization has focused on public presentation and asynchronous individual consumption, such as in the domain of journalism. The visualization research community knows comparatively little about synchronous and multimodal communication around data within organizations, from team meetings to executive briefings. We conducted two qualitative interview studies with individuals who prepare and deliver presentations about data to audiences in organizations. In contrast to prior work, we did not limit our interviews to those who self-identify as data analysts or data scientists. Both studies examined aspects of speaking about data with visual aids such as charts, dashboards, and tables. One study was a retrospective examination of current practices and difficulties, from which we identified three scenarios involving presentations of data. We describe these scenarios using an analogy to musical performance: small collaborative team meetings are akin to jam session, while more structured presentations can range from semi-improvisational performances among peers to formal recitals given to executives or customers. In our second study, we grounded the discussion around three design probes, each examining a different aspect of presenting data: the progressive reveal of visualization to direct attention and advance a narrative, visualization presentation controls that are hidden from the audience’s view, and the coordination of a presenter’s video with interactive visualization. Our distillation of interviewees’ responses surfaced twelve themes, from ways of authoring presentations to creating accessible and engaging audience experiences.","Interviews, design probes, presentation, communication, collaboration, business intelligence, qualitative research.",Matthew,Brehmer,Robert,Kosara,,,,,,,,,,,,,,,,,,,,,,,Matthew Brehmer: Tableau Research; Robert Kosara: Tableau Research,rkosara@tableau.com
Representations & Interaction,1072,Kineticharts: Augmenting Affective Expressiveness of Charts in Data Stories with Animation Design,"Data stories often seek to elicit affective feelings from viewers. However, how to design affective data stories remains under-explored. In this work, we investigate one specific design factor, animation, and present Kineticharts, an animation design scheme for creating charts that express five positive affects: joy, amusement, surprise, tenderness, and excitement. These five affects were found to be frequently communicated through animation in data stories. Regarding each affect, we designed varied kinetic motions represented by bar charts, line charts, and pie charts, resulting in 60 animated charts for the five affects. We designed Kineticharts by first conducting a need-finding study with professional practitioners from data journalism and then analyzing a corpus of affective motion graphics to identify salient kinetic patterns. We evaluated Kineticharts through two user studies. The results suggest that Kineticharts can accurately convey affects, and improve the expressiveness of data stories, as well as enhance user engagement without hindering data comprehension compared to the animation design from DataClips, an authoring tool for data videos.","Animation, Storytelling, Affective Design",Xingyu,Lan,Yang,Shi,Yanqiu,Wu,Xiaohan,Jiao,Nan,Cao,,,,,,,,,,,,,,,,,Xingyu Lan: Tongji University; Yang Shi: Tongji University; Yanqiu Wu: Tongji University; Xiaohan Jiao: Tongji College of Design and Innovation; Nan Cao: Tongji College of Design and Innovation,shiyang1230@gmail.com; wuyanqiu23@gmail.com; jiaoxiaohan258@gmail.com; nan.cao@gmail.com
Data Transformations,1098,STNet: An End-to-End Generative Framework for Synthesizing Spatiotemporal Super-Resolution Volumes,"We present STNet, an end-to-end generative framework that synthesizes spatiotemporal super-resolution volumes with high fidelity for time-varying data. STNet includes two modules: a generator and a spatiotemporal discriminator. The input to the generator is two low-resolution volumes at both ends, and the output is the intermediate and the two-ending spatiotemporal super- resolution volumes. The spatiotemporal discriminator, leveraging convolutional long short-term memory, accepts a spatiotemporal super-resolution sequence as input and predicts a conditional score for each volume based on its spatial (the volume itself) and temporal (the previous volumes) information. We propose an unsupervised pre-training stage using cycle loss to improve the generalization of STNet. Once trained, STNet can generate spatiotemporal super-resolution volumes from low-resolution ones, offering scientists an option to save data storage (i.e., sparsely sampling the simulation output in both spatial and temporal dimensions). We compare STNet with the baseline bicubic+linear interpolation, two deep learning solutions (SSR+TSR, STD), and a state-of-the-art tensor compression solution (TTHRESH) to show the effectiveness of STNet.",Time-varying data; generative adversarial network; spatiotemporal super-resolution,Jun,Han,Hao,Zheng,Danny,Chen,Chaoli,Wang,,,,,,,,,,,,,,,,,,,Jun Han: University of Notre Dame; Hao Zheng: University of Notre Dame; Danny Z Chen: University of Notre Dame; Chaoli Wang: University of Notre Dame,jhan5@nd.edu; dchen@nd.edu; chaoli.wang@nd.edu
Data Transformations,1103,KG4Vis: A Knowledge Graph-Based Approach for Visualization Recommendation,"Visualization recommendation or automatic visualization generation can significantly lower the barriers for general users to rapidly create effective data visualizations, especially for those users without a background in data visualizations. However, existing rule-based approaches require tedious manual specifications of visualization rules by visualization experts. Other machine learning-based approaches often work like black-box and are difficult to understand why a specific visualization is recommended, limiting the wider adoption of these approaches. This paper fills the gap by presenting KG4Vis, a knowledge graph (KG)-based approach for visualization recommendation. It does not require manual specifications of visualization rules and can also guarantee good explainability. Specifically, we propose a framework for building knowledge graphs, consisting of three types of entities (i.e., data features, data columns and visualization design choices) and the relations between them, to model the mapping rules between data and effective visualizations. A TransE-based embedding technique is employed to learn the embeddings of both entities and relations of the knowledge graph from existing dataset-visualization pairs. Such embeddings intrinsically model the desirable visualization rules. Then, given a new dataset, effective visualizations can be inferred from the knowledge graph with semantically meaningful rules. We conducted extensive evaluations to assess the proposed approach, including quantitative comparisons, case studies and expert interviews. The results demonstrate the effectiveness of our approach.","Data visualization, Visualization recommendation, Knowledge graph",Haotian,Li,Yong,Wang,Songheng,Zhang,Yangqiu,Song,Huamin,Qu,,,,,,,,,,,,,,,,,"Haotian Li: The Hong Kong University of Science and Technology; Yong Wang: Singapore Management University; Songheng Zhang: University of California, Irvine; Yangqiu Song: Hong Kong University of Science and Technology; Huamin Qu: The Hong Kong University of Science and Technology",yongwang@smu.edu.sg; alexanderzhang117@gmail.com; yqsong@cse.ust.hk; huamin@cse.ust.hk
Theoretical & Empirical,1106,What’s the Situation with Situated Visualization? A Survey and Perspectives on Situatedness,"Situated visualization is an emerging concept within information visualization, in which data is visualized in situ, where it is relevant to people. The concept has gained interest from multiple research communities, including information visualization, human-computer interaction and augmented reality. This has led to a range of explorations and applications of the concept, however, this early work has focused on the operational aspect of situatedness leading to inconsistent adoption of the concept and terminology.  
First, we contribute a literature survey in which we analyze 40 papers that explicitly use the term ""situated visualization"" to provide an overview of the research area, how it defines situated visualization, common application areas and technology used, as well as type of data and type of visualizations. Our survey shows that research on situated visualization has focused on technology-centric approaches that forefront a spatial understanding of situatedness. 
Secondly, we contribute five perspectives on situatedness (space, time, place, activity, and community) that expand on the prevalent notion of situatedness in the corpus. We draw from six case studies and prior theoretical developments in HCI. Each perspective develops a generative way of looking at and working with situatedness in design and research. We outline future directions, including considering technology, material and aesthetics, leveraging the perspectives for design, and methods for stronger engagement with target audiences. We conclude with opportunities to consolidate situated visualization research.","Situated visualization, literature survey, situatedness",Nathalie,Bressa,Henrik,Korsgaard,Aurélien,Tabard,Steven,Houben,Jo,Vermeulen,,,,,,,,,,,,,,,,,Nathalie Bressa: Aarhus University; Henrik Korsgaard: Aarhus University; Aurélien Tabard: Université de Lyon; Steven Houben: Lancaster University; Jo Vermeulen: Autodesk Research,korsgaard@cs.au.dk; aurelien@tabard.fr; s.houben@tue.nl; jo.vermeulen@autodesk.com
Applications,1107,E-ffective: A Visual Analytic System for Exploring the Emotion and Effectiveness of Inspirational Speeches,"What makes speeches effective has long been a subject for debate, and until today there is broad controversy among public speaking experts about what factors make a speech effective as well as the roles of these factors in speeches. Moreover, there is a lack of quantitative analysis methods to help understand effective speaking strategies. In this paper, we propose E-ffective, a visual analytic system allowing speaking experts and novices to analyze both the role of speech factors and their contribution in effective speeches. From interviews with domain experts and investigating existing literature, we figured out important factors to consider in inspirational speeches. We obtained the generated factors from multi-modal data that were then related to effectiveness data. Our system supports rapid understanding of critical factors in inspirational speeches, including the influence of emotions by means of novel visualization methods and interaction. Two novel visualizations include E-spiral (that shows the emotional shifts in speeches in a visually compact way) and E-script (that connects speech content with key speech delivery information). In our evaluation we studied the influence of our system on experts' domain knowledge about speech factors. We further studied the usability of the system by speaking novices and experts on assisting analysis of inspirational speech effectiveness.","Affective visualization, multimodal analysis, speech effectiveness",Kevin,Maher,Zeyuan,Huang,Jiancheng,Song,Xiaoming,Deng,Yu-Kun,Lai,Cuixia,Ma,Hao,Wang,Yong-Jin,Liu,Hongan,Wang,,,,,,,,,"Kevin Maher: Institute of Software, Chinese Academy of Sciences; Zeyuan Huang: Institute of Software, Chinese Academy of Sciences; Jiancheng Song: Institute of Software, Chinese Academy of Sciences; Xiaoming Deng: Institute of Software, Chinese Academy of Sciences; Yu-Kun Lai: Cardiff University; Cuixia Ma: Institute of Software, Chinese Academy of Sciences; Hao Wang: Alibaba group; Yong-Jin Liu: Tsinghua University; Hongan Wang: Institute of Software, Chinese Academy of Sciences",kevintmaher@gmail.com; songjc1996@gmail.com; xiaoming@iscas.ac.cn; yukun.lai@cs.cardiff.ac.uk; cuixia@iscas.ac.cn; cashenry@126.com; liuyongjin@tsinghua.edu.cn; hongan@iscas.ac.cn
Analytics & Decisions,1112,M^2Lens: Visualizing and Explaining Multimodal Models for Sentiment Analysis,"Multimodal sentiment analysis aims to recognize people’s attitudes from
multiple communication channels such as verbal content (i.e., text), voice, and facial expressions. It has become a vibrant and important research topic in natural language processing. Much research focuses on modeling the complex intra- and inter-modal interactions between different communication channels.
However, current multimodal models with strong performance are often deep-learning-based techniques and work like black boxes.
It is not clear how models utilize multimodal information for sentiment predictions.
Despite recent advances in techniques for enhancing the explainability of machine learning models, they often target unimodal scenarios (e.g., images, sentences),
and little research has been done on explaining multimodal models.
In this paper, we present an interactive visual analytics system, M2Lens, to visualize and explain multimodal models for sentiment analysis. M2Lens provides explanations on intra- and inter-modal interactions at the global, subset, and local levels. Specifically, it summarizes the influence of three typical interaction types (i.e., dominance, complement, and conflict) on the model predictions. 
Moreover, M2Lens identifies frequent and influential multimodal features and supports the multi-faceted exploration of model behaviors from language, acoustic, and visual modalities.
Through two case studies and expert interviews, we demonstrate our system can help users gain deep insights into the multimodal models for sentiment analysis.","Multimodal models, sentiment analysis, explainable machine learning",Xingbo,Wang,Jianben,He,Zhihua,Jin,Muqiao,Yang,Yong,Wang,Huamin,Qu,,,,,,,,,,,,,,,Xingbo Wang: The Hong Kong University of Science and Technology; Jianben He: The Hong Kong University of Science and Technology; Zhihua Jin: Hong Kong University of Science and Technology; Muqiao Yang: Carnegie Mellon University; Yong Wang: Singapore Management University; Huamin Qu: The Hong Kong University of Science and Technology,jhebt@connect.ust.hk; zjinak@connect.ust.hk; muqiaoy@cs.cmu.edu; yongwang@smu.edu.sg; huamin@cse.ust.hk
Applications,1113,Visual Analysis of Hyperproperties for Understanding Model Checking Results,"Model checkers provide algorithms for proving that a mathematical model of a system satisfies a given specification. In case of a violation, a counterexample that shows the erroneous behavior is returned. Understanding these counterexamples is challenging, especially for hyperproperty specifications, i.e., specifications that relate multiple executions of a system to each other. We aim to facilitate the visual analysis of such counterexamples through our HyperVis tool, which provides interactive visualizations of the given model, specification, and counterexample. Within an iterative and interdisciplinary design process, we developed visualization solutions that can effectively communicate the core aspects of the model checking result. Specifically, we introduce graphical representations of binary values for improving pattern recognition, color encoding for better indicating related aspects, visually enhanced textual descriptions, as well as extensive cross-view highlighting mechanisms. Further, through an underlying causal analysis of the counterexample, we are also able to identify values that contributed to the violation and use this knowledge for both improved encoding and highlighting. Finally, the analyst can modify both the specification of the hyperproperty and the system directly within HyperVis and initiate the model checking of the new version. In combination, these features notably support the analyst in understanding the error leading to the counterexample as well as iterating the provided system and specification. We ran multiple case studies with HyperVis and tested it with domain experts in qualitative feedback sessions. The participants' positive feedback confirms the considerable improvement over the manual, text-based status quo and the value of the tool for explaining hyperproperties.","Analyzing Counterexamples, Linked Brushing, Multiple Coordinate Views, Explainable Formal Methods",Tom,Horak,Norine,Coenen,Niklas,Metzger,Christopher,Hahn,Tamara,Flemisch,Julián,Méndez,Dennis,Dimov,Bernd,Finkbeiner,Raimund,Dachselt,,,,,,,,,Tom Horak: Technische Universität Dresden; Norine Coenen: CISPA Helmholtz Center for Information Security; Niklas Metzger: CISPA Helmholtz Center for Information Security; Christopher Hahn: CISPA Helmholtz Center for Information Security; Tamara Flemisch: Technische Universität Dresden; Julián Méndez: Technische Universität Dresden; Dennis Dimov: Technische Universität Dresden; Bernd Finkbeiner: CISPA Helmholtz Center for Information Security; Raimund Dachselt: Technische Universität Dresden,norine.coenen@cispa.saarland; niklas.metzger@cispa.saarland; christopher.hahn@cispa.saarland; tamara.flemisch@posteo.de; menoc.sk27@gmail.com; dennis.dimov@mailbox.tu-dresden.de; finkbeiner@cispa.saarland; dachselt@acm.org
Analytics & Decisions,1116,Sequen-C: A Multilevel Overview of Temporal Event Sequences,"Building a visual overview of temporal event sequences with an optimal level-of-detail (i.e. simplified but informative) is an ongoing challenge - expecting the user to zoom into every important aspect of the overview can lead to missing insights. We propose a technique to build and explore a multilevel overview of event sequences, from coarse to fine vertical or horizontal level-of-detail, using hierarchical aggregation and a novel cluster data representation Align-Score-Simplify.  By default, the overview shows an optimal number of sequence clusters obtained through the average silhouette width metric – then users are able to explore alternative optimal sequence clusterings. The vertical level-of-detail of the overview changes along with the number of clusters, whilst the horizontal level-of-detail refers to the level of summarization applied to each cluster representation. The proposed technique has been implemented into a visualization system called Sequence Cluster Explorer (Sequen-C) that allows multilevel and detail-on-demand exploration through three coordinated views, and the inspection of data attributes at cluster, unique sequence, and individual sequence level. We present two case studies using real-world datasets in the healthcare domain: CUREd and MIMIC-III, which demonstrate how the technique can aid users in exploring and defining a set of distinct pathways that best summarize the dataset, while also being able of identifying deviating pathways and exploring data attributes for selected patterns.","Temporal event sequence visualization, clustering, hierarchical aggregation, multiple sequence alignment",Jessica,Magallanes,Tony,Stone,Paul,Morris,Suzanne,Mason,Steven,Wood,Maria-Cruz,Villa-Uriol,,,,,,,,,,,,,,,Jessica Magallanes: University of Sheffield; Tony Stone: University of Sheffield; Paul D Morris MRCP PhD: University of Sheffield; Suzanne Mason: University of Sheffield; Steven Wood: Sheffield Teaching Hospitals Foundation Trust; Maria-Cruz Villa-Uriol: University of Sheffield ,tony.stone@sheffield.ac.uk; paul.morris@sheffield.ac.uk; s.mason@sheffield.ac.uk; steven.wood8@nhs.net; m.villa-uriol@sheffield.ac.uk
Systems & Rendering,1119,Propagating Visual Designs to Numerous Plots and Dashboards,"In the process of developing an infrastructure for providing visualization and visual analytics (VIS) tools to epidemiologists and modeling scientists, we encountered a technical challenge for applying a number of visual designs to numerous datasets rapidly and reliably with limited development resources. In this paper, we present a technical solution to address this challenge. Operationally, we separate the tasks of data management, visual designs, and plots and dashboard deployment in order to streamline the development workflow. Technically, we utilize: an ontology to bring datasets, visual designs, and deployable plots and dashboards under the same management framework; multi-criteria search and ranking algorithms for discovering potential datasets that match a visual design; and a purposely-design user interface for propagating each visual design to appropriate datasets (often in tens and hundreds) and quality-assuring the propagation before the deployment. This technical solution has been used in the development of the RAMPVIS infrastructure for supporting a consortium of epidemiologists and modeling scientists through visualization.","Visualization system, propagation, infrastructure, ontology, quality assurance, pandemic, emergency response",Saiful,Khan,Phong,Nguyen,Alfie,Abdul-Rahman,Benjamin,Bach,Min,Chen,Euan,Freeman,Cagatay,Turkay,,,,,,,,,,,,,Saiful Khan: University of Oxford; Phong H. Nguyen: Redsift Ltd.; Alfie Abdul-Rahman: King's College London; Benjamin Bach: Edinburgh University; Min Chen: University of Oxford; Euan Freeman: University of Glasgow; Cagatay Turkay: University of Warwick,saiful.etc@gmail.com; phonghainguyen84@gmail.com; bbach@inf.ed.ac.uk; min.chen@oerc.ox.ac.uk; euan04@gmail.com; cagatay.turkay@warwick.ac.uk
Analytics & Decisions,1123,Towards Visual Explainable Active Learning for Zero-Shot Classification,"Zero-shot classification is a promising paradigm to solve an applicable problem when the training classes and test classes are disjoint. Achieving this usually needs experts to externalize their domain knowledge by manually specifying a class-attribute matrix to define which classes have which attributes. Designing a suitable class-attribute matrix is the key to the subsequent procedure, but this design process is tedious and trial-and-error with no guidance. This paper proposes a visual explainable active learning approach with its design and implementation called semantic navigator to solve the above problems. This approach promotes human-AI teaming with four actions (ask, explain, recommend, respond) in each interaction loop. The machine asks contrastive questions to guide humans in the thinking process of attributes. A novel visualization called semantic map explains the current status of the machine. Therefore analysts can better understand why the machine misclassifies objects. Moreover, the machine recommends the labels of classes for each attribute to ease the labeling burden. Finally, humans can steer the model by modifying the labels interactively, and the machine adjusts its recommendations. The visual explainable active learning approach improves humans' efficiency of building zero-shot classification models interactively, compared with the method without guidance. We justify our results with user studies using the standard benchmarks for zero-shot classification.","Active Learning, Explainable Artificial Intelligence, Human-AI Teaming, Mixed-Initiative Visual Analytics, Guided Interactive Zero-Shot Classification",Shichao,Jia,zeyu,li,Nuo,Chen,Jiawan,Zhang,,,,,,,,,,,,,,,,,,,Shichao Jia: Tianjin University; zeyu li: Visual Computing Lab; Nuo Chen: Tianjin University ; Jiawan Zhang: Tianjin University,lzytianda@tju.edu.cn; nicole_0420@tju.edu.cn; jwzhang@tju.edu.cn
Analytics & Decisions,1135,TacticFlow: Visual Analytics of Ever-Changing Tactics in Racket Sports,"Event sequence mining is often used to summarize patterns from hundreds of sequences but faces special challenges when handling racket sports data. In racket sports (e.g., tennis and badminton), a player hitting the ball is considered a multivariate event consisting of multiple attributes (e.g., hit technique and ball position). A rally (i.e., a series of consecutive hits beginning with one player serving the ball and ending with one player winning a point) thereby can be viewed as a multivariate event sequence. Mining frequent patterns and depicting how patterns change over time is instructive and meaningful to players who want to learn more short-term competitive strategies (i.e., tactics) that encompass multiple hits. However, players in racket sports usually change their tactics rapidly according to the opponent’s reaction, resulting in ever-changing tactic progression. In this work, we introduce a tailored visualization system built on a novel multivariate sequence pattern mining algorithm to facilitate explorative identification and analysis of various tactics and tactic progression.  The algorithm can mine multiple non-overlapping multivariate patterns from hundreds of sequences effectively. Based on the mined results, we propose a glyph-based Sankey diagram to visualize the ever-changing tactic progression and support interactive data exploration. Through two case studies with four domain experts in tennis and badminton, we demonstrate that our system can effectively obtain insights about tactic progression in most racket sports. We further discuss the strengths and the limitations of our system based on domain experts’ feedback.","Sports Analytics, Multivariate Event Sequence, Sequential Pattern Mining, Progression Analysis.",Jiang,Wu,Dongyu,Liu,Ziyang,Guo,Qingyang,Xu,Yingcai,Wu,,,,,,,,,,,,,,,,,Jiang Wu: Zhejiang University; Dongyu Liu: MIT; Ziyang Guo: Zhejiang University; Qingyang Xu: Zhejiang University; Yingcai Wu: Zhejiang University,ustdongyu@gmail.com; ziyangguo1030@gmail.com; qingyangxu17@gmail.com; ycwu@zju.edu.cn
Theoretical & Empirical,1136,Differentiable Direct Volume Rendering,"We present a differentiable volume rendering solution that provides differentiability of all continuous parameters of the volume rendering process. This differentiable renderer is used to steer the parameters towards a setting with an optimal solution of a problem-specific objective function. We have tailored the approach to volume rendering by enforcing a constant memory footprint via analytic inversion of the blending functions. This makes it independent of the number of sampling steps through the volume and facilitates the consideration of small-scale changes. The approach forms the basis for automatic optimizations regarding external parameters of the rendering process and the volumetric density field itself. We demonstrate its use for automatic viewpoint selection using differentiable entropy as objective, and for optimizing a transfer function from rendered images of a given volume. Optimization of per-voxel densities is addressed in two different ways: First, we mimic inverse tomography and optimize a 3D density field from images using an absorption model. This simplification enables comparisons with algebraic reconstruction techniques and state-of-the-art differentiable path tracers. Second, we introduce a novel approach for tomographic reconstruction from images using an emission-absorption model with post-shading via an arbitrary transfer function.","Differentiable rendering, Direct Volume Rendering, Automatic Differentiation",Sebastian,Weiss,Rüdiger,Westermann,,,,,,,,,,,,,,,,,,,,,,,Sebastian Weiss: Technical University of Munich; Rüdiger Westermann: Technical University of Munich,westermann@tum.de
Theoretical & Empirical,1145,Towards Understanding Sensory Substitution for Accessible Visualization: An Interview Study,"For all its potential in supporting data analysis, particularly in exploratory situations, visualization also creates barriers: accessibility for blind and visually impaired individuals. Regardless of how effective a visualization is, providing equal access for blind users requires a paradigm shift for the visualization research community. To enact such a shift, it is not sufficient to treat visualization accessibility as merely another technical problem to overcome. Instead, supporting the millions of blind and visually impaired users around the world who have equally valid needs for data analysis as sighted individuals requires a respectful, equitable, and holistic approach that includes all users from the onset. In this paper, we draw on accessibility research methodologies to make inroads towards such an approach. We first identify the people who have specific insight into how blind people perceive the world: orientation and mobility (O&M) experts, who are instructors that teach blind individuals how to navigate the physical world using non-visual senses. We interview 10 O&M experts—all of them blind—to understand how best to use sensory substitution other than the visual sense for conveying spatial layouts. Finally, we investigate our qualitative findings using thematic analysis. While blind people in general tend to use both sound and touch to understand their surroundings, we focused on auditory affordances and how they can be used to make data visualizations accessible—using sonification and auralization. However, our experts recommended supporting a combination of senses—sound and touch—to make charts accessible as blind individuals may be more familiar with exploring tactile charts. We report results on both sound and touch affordances, and conclude by discussing implications for accessible visualization for blind individuals.","Accessibility, blind users, sonification, visualization, spatial layouts, sound perception.",Pramod,Chundury,Biswaksen,Patnaik,Yasmin,Reyazuddin,Christine,Tang,Jonathan,Lazar,Niklas,Elmqvist,,,,,,,,,,,,,,,"Pramod Chundury: University of Maryland; Biswaksen Patnaik: University of Maryland College Park; Yasmin Reyazuddin: National Federation of the Blind; Christine W Tang: Poolesville High School; Jonathan Lazar: University of Maryland; Niklas Elmqvist: University of Maryland, College Park",bpatnaik@umd.edu; yasmin81065@yahoo.com; christinetang075@gmail.com; jlazar@umd.edu; elm@umd.edu
Theoretical & Empirical,1148,"Left, Right, and Gender: Exploring Interaction Traces to Mitigate Human Biases","Human biases impact the way people analyze data and make decisions. Recent work has shown that some visualization designs can better support cognitive processes and mitigate cognitive biases (i.e., errors that occur due to the use of mental “shortcuts”). In this work, we explore how visualizing a user’s interaction history (i.e., which data points a user has interacted with) can be used to mitigate potential biases that drive decision making by promoting conscious reflection of one’s analysis process. Given an interactive scatterplot-based visualization tool, we showed interaction history in real-time while exploring data (e.g., by coloring points in the scatterplot that the user has interacted with), and in a summative format after a decision has been made (e.g., by comparing the distribution of user interactions to the underlying distribution of the data). We conducted a series of in-lab experiments and a crowdsourced experiment to evaluate the effectiveness of interaction history interventions toward mitigating bias. We contextualized this work in a political scenario in which participants were instructed to choose a committee of 10 fictitious politicians to review a recent bill passed in the U.S. state of Georgia banning abortion after 6 weeks, where e.g. gender bias or political party bias may drive one’s analysis process. We demonstrate the generalizability of this approach by evaluating a second decision making scenario related to movies. Our results are inconclusive for the effectiveness of interaction history (henceforth referred to as interaction traces) toward mitigating biased decision making. However, we find some mixed support that interaction traces, particularly in a summative format, can increase awareness of potential unconscious biases.","Human bias, bias mitigation, visual data analysis",Emily,Wall,Arpit,Narechania,Adam,Coscia,Jamal,Paden,Alex,Endert,,,,,,,,,,,,,,,,,Emily Wall: Emory University; Arpit Narechania: Georgia Institute of Technology; Adam J Coscia: Georgia Institute of Technology; Jamal Paden: Georgia Tech; Alex Endert: Georgia Institute of Technology,arpitnarechania@gatech.edu; acoscia6@gatech.edu; jpaden@gatech.edu; endert@gatech.edu
Applications,1149,VitaLITy: Promoting Serendipitous Discovery of Academic Literature with Transformers & Visual Analytics,"There are a few prominent practices for conducting reviews of academic literature, including searching for specific keywords on Google Scholar or checking citations from some initial seed paper(s). These approaches serve a critical purpose for academic literature reviews, yet there remain challenges in identifying relevant literature when similar work may utilize different terminology (e.g., mixed-initiative visual analytics papers may not use the same terminology as papers on model-steering, yet the two topics are relevant to one another). In this paper, we introduce a system, VITALITY, intended to complement existing practices. In particular, VITALITY promotes serendipitous discovery of relevant literature using transformer language models, allowing users to find semantically similar papers in a word embedding space given (1) a list of input paper(s) or (2) a working abstract. VITALITY visualizes this document-level embedding space in an interactive 2-D scatterplot using dimension reduction. VITALITY also summarizes meta information about the document corpus or search query, including keywords and co authors, and allows users to save and export papers for use in a literature review. We present qualitative findings from an evaluation of VITALITY, suggesting it can be a promising complementary technique for conducting academic literature reviews. Furthermore, we contribute data from 38 popular data visualization publication venues in VITALITY, and we provide scrapers for the open-source community to continue to grow the list of supported venues.","transformers, word embeddings, literature review, visual analytics",Arpit,Narechania,Alireza,Karduni,Ryan,Wesslen,Emily,Wall,,,,,,,,,,,,,,,,,,,Arpit Narechania: Georgia Institute of Technology; Alireza Karduni: UNC Charlotte; Ryan Wesslen: UNC Charlotte; Emily Wall: Northwestern University,arpitnarechania@gatech.edu; alireza.karduni@northwestern.edu; rwesslen@uncc.edu
Representations & Interaction,1155,Rotate or Wrap? Interactive Visualisations of Cyclical Data on Cylindrical or Toroidal Topologies,"In this paper, we report on a study of visual representations for cyclical data and the effect of interactively wrapping a bar chart ‘around its boundaries’. Compared to linear bar chart, polar (or radial) visualisations have the advantage that cyclical data can be presented continuously without mentally bridging the visual ‘cut’ across the left-and-right boundaries. To investigate this hypothesis and to assess the effect the cut has on analysis performance, this paper presents results from a crowdsourced, controlled experiment with 72 participants comparing new continuous panning technique to linear bar charts (interactive wrapping). Our results show that bar charts with interactive wrapping lead to less errors compared to standard bar charts or polar charts. Inspired by these results, we generalise the concept of interactive wrapping to other visualisations for cyclical or relational data. We describe a design space based on the concept of one-dimensional wrapping and two-dimensional wrapping, linked to two common 3D topologies; cylinder and torus that can be used to metaphorically explain one- and two-dimensional wrapping. This design space suggests that interactive wrapping is widely applicable to many different data types.","Cyclic temporal data, cylindrical topologies, toroidal topologies, interaction techniques, bar charts, polar charts, crowdsourced experiment",Kun-Ting,Chen,Tim,Dwyer,Benjamin,Bach,Kim,Marriott,,,,,,,,,,,,,,,,,,,Kun-Ting Chen: Monash University; Tim Dwyer: Monash University; Benjamin Bach: Edinburgh University; Kim Marriott: Monash University,tgdwyer@gmail.com; bbach@inf.ed.ac.uk; kim.marriott@monash.edu
Representations & Interaction,1160,Perception! Immersion! Empowerment! Superpowers as Inspiration for Visualization,"We explore how the lens of fictional superpowers can help characterize how visualizations empower people and provide inspiration for new visualization systems. Researchers and practitioners often tout visualizations’ ability to “make the invisible visible”and to “enhance cognitive abilities.”  Meanwhile superhero comics and other modern fiction often depict characters with similarly fantastic abilities that allow them to see and interpret the world in ways that transcend traditional human perception. We investigate the intersection of these domains, and show how the language of superpowers can be used to characterize existing visualization systems and suggest opportunities for new and empowering ones. We introduce two frameworks: The first characterizes seven underlying mechanics that form the basis for a variety of visual superpowers portrayed in fiction.  The second identifies seven ways in which visualization tools and interfaces can instill a sense of empowerment in the people who use them. Building on these observations, we illustrate a diverse set of “visualization superpowers” and highlight opportunities for the visualization community to create new system sand interactions that empower new experiences with data","Visualization, superpowers, empowerment, vision, perception, cognition, fiction, situated visualization",Wesley,Willett,Bon Adriel,Aseniero,Sheelagh,Carpendale,Pierre,Dragicevic,Yvonne,Jansen,Lora,Oehlberg,Petra,Isenberg,,,,,,,,,,,,,"Wesley Willett: University of Calgary; Bon Adriel Aseniero: Autodesk Research; Sheelagh Carpendale: Simon Fraser University; Pierre Dragicevic: Université Paris-Saclay, CNRS, Inria, LISN; Yvonne Jansen: Sorbonne Université, CNRS, ISIR; Lora Oehlberg: University of Calgary; Petra Isenberg: Université Paris-Saclay, CNRS, Inria, LISN",bon.aseniero@autodesk.com; sheelagh@sfu.ca; pierre.dragice@gmail.com; yvonne.jansen@sorbonne-universite.fr; lora.oehlberg@ucalgary.ca; petra.isenberg@inria.fr
Data Transformations,1163,"Wasserstein Distances, Geodesics and Barycenters of Merge Trees","This paper presents a unified computational framework for the estimation of distances, geodesics and barycenters of merge trees. We extend recent work on the edit distance and introduce a new metric, called the Wasserstein distance between merge trees, which is purposely designed to enable efficient computations of geodesics and barycenters. Specifically, our new distance is strictly equivalent to the L 2 -Wasserstein distance between extremum persistence diagrams, but it is restricted to a smaller solution space, namely, the space of rooted partial isomorphisms between branch decomposition trees. This enables a simple extension of existing optimization frameworks for geodesics and barycenters from persistence diagrams to merge trees. We introduce a task-based algorithm which can be generically applied to distance, geodesic, barycenter or cluster computation. The task-based nature of our approach enables further accelerations with shared-memory parallelism. Extensive experiments on public ensembles and SciVis contest benchmarks demonstrate the efficiency of our approach – with barycenter computations in the orders of minutes for the largest examples – as well as its qualitative ability to generate representative barycenter merge trees, visually summarizing the features of interest found in the ensemble. We show the utility of our contributions with dedicated visualization applications: feature tracking, temporal reduction and ensemble clustering. We provide a lightweight C++ implementation that can be used to reproduce our results.",Scalar Field Data ; Algorithms ; Data Abstractions & Types ; Computational Topology-based Techniques ; Comparison and Similarity,Mathieu,Pont,Jules,Vidal,Julie,Delon,Julien,Tierny,,,,,,,,,,,,,,,,,,,Mathieu Pont: CNRS; Jules Vidal: Sorbonne Université ; Julie Delon: Université de Paris; Julien Tierny: CNRS,jules.vidal@lip6.fr; julie.delon@u-paris.fr; julien.tierny@sorbonne-universite.fr
Analytics & Decisions,1181,Compass: Towards Better Causal Analysis of Urban Time Series,"The spatial time series generated by city sensors allow us to observe urban phenomena like environmental pollution and traffic congestion at an unprecedented scale. However, recovering causal relations from these observations to explain the sources of urban phenomena remains a challenging task because these causal relations tend to be time-varying and demand proper time series partitioning for effective analyses. The prior approaches extract one causal graph given long-time observations, which cannot be directly applied to capturing, interpreting, and validating dynamic urban causality. This paper presents Compass, a novel visual analytics approach for in-depth analyses of the dynamic causality in urban time series. To develop Compass, we identify and address three challenges: detecting urban causality, interpreting dynamic causal relations, and unveiling suspicious causal relations. First, multiple causal graphs over time among urban time series are obtained with a causal detection framework extended from the Granger causality test. Then, a dynamic causal graph visualization is designed to reveal the time-varying causal relations across these causal graphs and facilitate the exploration of the graphs along the time. Finally, a tailored multi-dimensional visualization is developed to support the identification of spurious causal relations, thereby improving the reliability of causal analyses. The effectiveness of Compass is evaluated with two case studies conducted on the real-world urban datasets, including the air pollution and traffic speed datasets, and positive feedback was received from domain experts.","Visual causal analysis, urban time series, causal graph analysis.",Zikun,Deng,Di,Weng,Xiao,Xie,Jie,Bao,Yu,Zheng,Mingliang,Xu,Wei,Chen,Yingcai,Wu,,,,,,,,,,,Zikun Deng: Zhejiang University; Di Weng: Zhejiang University; Xiao Xie: Zhejiang University; Jie Bao: JD Tech; Yu Zheng: JD Tech; Mingliang Xu: Zhengzhou University; Wei Chen: Zhejiang University; Yingcai Wu: Zhejiang University,mystery.wd@gmail.com; xxie@zju.edu.cn; jie.bao@hotmail.com; msyuzheng@outlook.com; iexumingliang@zzu.edu.cn; chenvis@zju.edu.cn; ycwu@zju.edu.cn
Applications,1187,IRVINE: Using Interactive Clustering and Labeling to Analyze Correlation Patterns: A Design Study from the Manufacturing of Electrical Engines,"In this design study, we present IRVINE, a Visual Analytics (VA) system, which facilitates the analysis of acoustic data to detect and understand previously unknown errors in the manufacturing of electrical engines. In serial manufacturing processes, signatures from acoustic data provide valuable information on how the relationship between multiple produced engines serves to detect and understand previously unknown errors. To analyze such signatures, IRVINE leverages interactive clustering and data labeling techniques, allowing users to analyze clusters of engines with similar signatures, drill down to groups of engines, and select an engine of interest. Furthermore, IRVINE allows to assign labels to engines and clusters and annotate the cause of an error in the acoustic raw measurement of an engine. Since labels and annotations represent valuable knowledge, they are conserved in a knowledge database to be available for other stakeholders. We contribute a design study, where we developed IRVINE in four main iterations with engineers from a company in the automotive sector. To validate IRVINE, we conducted a field study with six domain experts. Our results suggest a high usability and usefulness of IRVINE as part of the improvement of a real-world manufacturing process. Specifically, with IRVINE domain experts were able to label and annotate produced electrical engines more than 30% faster.","Keywords: Design study, interactive labeling, interactive clustering

Index Terms: H.5.2 [Information Interfaces and Presentation]: User Interfaces—Graphical user interfaces (GUI); User-centered design",Joscha,Eirich,Jakob,Bonart,Dominik,Jäckle,Michael,Sedlmair,Ute,Schmid,Kai,Fischbach,Tobias,Schreck,Jürgen,Bernard,,,,,,,,,,,Joscha Eirich: University of Bamberg; Jakob Bonart: IWU Fraunhofer; Dominik Jäckle: Independent Researcher; Michael Sedlmair: University of Stuttgart; Ute Schmid: University of Bamberg; Kai Fischbach: University of Bamberg; Tobias Schreck: Graz University of Technology; Jürgen Bernard: University of Zurich,jakob.bonart@bmw.de; dominikjaeckle@gmail.com; michael.sedlmair@visus.uni-stuttgart.de; ute.schmid@uni-bamberg.de; kai.fischbach@uni-bamberg.de; tobias.schreck@cgv.tugraz.at; bernard@ifi.uzh.ch
Analytics & Decisions,1194,NeuroCartography: Scalable Automatic Visual Summarization of Concepts in Deep Neural Networks,"Existing research on making sense of deep neural networks often focuses on neuron-level interpretation, which may not adequately capture the bigger picture of how concepts are collectively encoded by multiple neurons. We present NeuroCartography, an interactive system that scalably summarizes and visualizes concepts learned by neural networks. It automatically discovers and groups neurons that detect the same concepts, and describes how such neuron groups interact to form higher-level concepts and the subsequent predictions. NeuroCartography introduces two scalable summarization techniques: (1) neuron clustering groups neurons based on the semantic similarity of the concepts detected by neurons (e.g., neurons detecting “dog faces” of different breeds are grouped); and (2) neuron embedding encodes the associations between related concepts based on how often they co-occur (e.g., neurons detecting “dog face” and “dog tail” are placed closer in the embedding space).  Key to our scalable techniques is the ability to efficiently compute all neuron pairs’ relationships, in time linear to the number of neurons instead of quadratic time. NeuroCartography scales to large data, such as the ImageNet dataset with 1.2M images. The system’s tightly coordinated views integrate the scalable techniques to visualize the concepts and their relationships, projecting the concept associations to a 2D space in Neuron Projection View, and summarizing neuron clusters and their relationships in Graph View. Through a large-scale human evaluation, we demonstrate that our technique discovers neuron groups that represent coherent, human-meaningful concepts. And through usage scenarios, we describe how our approaches enable interesting and surprising discoveries, such as concept cascades of related and isolated concepts. The NeuroCartography visualization runs in modern browsers and is open-sourced.","Deep learning interpretability, visual analytics, scalable summarization, neuron clustering, neuron embedding",Haekyu,Park,Nilaksh,Das,Rahul,Duggal,Austin,Wright,Omar,Shaikh,Fred,Hohman,Duen Horng,Chau,,,,,,,,,,,,,Haekyu Park: Georgia Institute of Technology; Nilaksh Das: Georgia Institute of Technology; Rahul Duggal: Georgia Institute of Technology; Austin P Wright: Georgia Institute of Technology ; Omar Shaikh: Georgia Institute of Technology; Fred Hohman: Georgia Institute of Technology; Duen Horng Chau: Georgia Tech,nilakshdas@gatech.edu; rahulduggal@gatech.edu; apwright@gatech.edu; oshaikh@gatech.edu; fred.hohman@gmail.com; polo@gatech.edu
Theoretical & Empirical,1198,Visualization Equilibrium,"In many real-world strategic settings, people use information displays to make decisions. In these settings, an information provider chooses which information to provide to strategic agents and how to present it, and agents formulate a best response based on the information and their anticipation of how others will behave.  We contribute the results of a controlled online experiment to examine how the provision and presentation of information impacts people's decisions in a congestion game. Our experiment compares how different visualization approaches for displaying this information, including bar charts and hypothetical outcome plots, and different information conditions, including where the visualized information is private versus public (i.e., available to all agents), affect decision making and welfare. We characterize the effects of visualization anticipation, referring to changes to behavior when an agent goes from alone having access to a visualization to knowing that others also have access to the visualization to guide their decisions. We also empirically identify the visualization equilibrium, i.e., the visualization for which the visualized outcome of agents' decisions matches the realized decisions of the agents who view it. We reflect on the implications of visualization equilibria and visualization anticipation for designing information displays for real-world strategic settings.","Visualization equilibrium, Uncertainty visualization, Strategic communication, Nash equilibrium.",Paula,Kayongo,Glenn,Sun,Jason,Hartline,Jessica,Hullman,,,,,,,,,,,,,,,,,,,"Paula Kayongo: Northwestern University; Glenn Sun: University of California, Los Angeles; Jason Hartline: Northwestern Univeristy; Jessica Hullman: Northwestern University",glennsun@g.ucla.edu; hartline@eecs.northwestern.edu; jhullman@northwestern.edu
Theoretical & Empirical,1199,An Evaluation-Focused Framework for Visualization Recommendation Algorithms,"Although we have seen a proliferation of algorithms for recommending visualizations, these algorithms are rarely compared with one another, making it difficult to ascertain which algorithm is best for a given visual analysis scenario. Though several formal frameworks have been proposed in response, we believe this issue persists because visualization recommendation algorithms are inadequately specified from an evaluation perspective. In this paper, we propose an evaluation-focused framework to contextualize and compare a broad range of visualization recommendation algorithms. We present the structure of our framework, where algorithms are specified using three components: (1) a graph representing the full space of possible visualization designs, (2) the method used to traverse the graph for potential candidates for recommendation, and (3) an oracle used to rank candidate designs. To demonstrate how our framework guides the formal comparison of algorithmic performance, we not only theoretically compare five existing representative recommendation algorithms, but also empirically compare four new algorithms generated based on our findings from the theoretical comparison. Our results show that these algorithms behave similarly in terms of user performance, highlighting the need for more rigorous formal comparisons of recommendation algorithms to further clarify their benefits in various analysis scenarios.","Visualization Tools, Visualization Recommendation Algorithms",Zehua,Zeng,Phoebe,Moh,Fan,Du,Jane,Hoffswell,Tak Yeon,Lee,Sana,Malik,Eunyee,Koh,Leilani,Battle,,,,,,,,,,,Zehua Zeng: University of Maryland; Phoebe Moh: University of Maryland; Fan Du: Adobe Research; Jane Hoffswell:  Adobe Research; Tak Yeon Lee: KAIST; Sana Malik: Adobe Research; Eunyee Koh: Adobe Research; Leilani Battle: University of Washington,pmoh@umd.edu; fdu@adobe.com; jhoffs@adobe.com; reflect9@gmail.com; sana.malik@adobe.com; eunyee@adobe.com; leibatt@cs.washington.edu
Data Transformations,1204,VizSnippets: Compressing Visualization Bundles Into Representative Previews for Browsing Visualization Collections,"Visualization collections, accessed by platforms such as Tableau Online or Power BI, are used by millions of people to share and access diverse analytical knowledge in the form of interactive visualization bundles. Result snippets, compact previews of these bundles, are presented to users to help them identify relevant content when browsing collections. Our engagement with Tableau product teams and review of existing snippet designs on five platforms showed us that current practices fail to help people judge the relevance of bundles because they include only the title and one image. Users frequently need to undertake the time-consuming endeavour of opening a bundle within its visualization system to examine its many views and dashboards. In response, we contribute the first systematic approach to visualization snippet design. We propose a framework for snippet design that addresses eight key challenges that we identify. We present a computational pipeline to compress the visual and textual content of bundles into representative previews that is adaptive to a provided pixel budget and provides high information density with multiple images and carefully chosen keywords. We also reflect on the method of visual inspection through random sampling to gain confidence in model and parameter choices.","visualization collections, visualization bundles, result snippets, visual inspection",Michael,Oppermann,Tamara,Munzner,,,,,,,,,,,,,,,,,,,,,,,Michael Oppermann: University of British Columbia; Tamara Munzner: University of British Columbia,tmm@cs.ubc.ca
Applications,1205,COVID-view: Diagnosis of COVID-19 using Chest CT,"Significant work has been done towards deep learning (DL) models for automatic lung and lesion segmentation and classification of COVID-19 on chest CT data. However, comprehensive visualization systems focused on supporting the dual visual+DL diagnosis of COVID-19 are non-existent. We present COVID-view, a visualization application specially tailored for radiologists to diagnose COVID-19 from chest CT data. The system incorporates a complete pipeline of automatic lungs segmentation, localization/isolation of lung abnormalities, followed by visualization, visual and DL analysis, and measurement/quantification tools. Our system combines the traditional 2D workflow of radiologists with newer 2D and 3D visualization techniques with DL support for a more comprehensive diagnosis. COVID-view incorporates a novel DL model for classifying the patients into positive/negative COVID-19 cases, which acts as a reading aid for the radiologist using COVID-view, and provides the attention heatmap as an explainable DL for the model output. We designed and evaluated COVID-view through suggestions, close feedback and conducting case studies of real-world patient data by expert radiologists who have substantial experience diagnosing chest CT scans for COVID-19, pulmonary embolism, and other forms of lung infections. We present requirements and task analysis for the diagnosis of COVID-19 that motivate our design choices and results in a practical system which is capable of handling real-world patient cases.","Visual+deep learning diagnosis, COVID-19, chest CT, volume rendering, MIP, classification model, explainable DL",Shreeraj,Jadhav,Gaofeng,Deng,Marlene,Zawin,Arie,Kaufman,,,,,,,,,,,,,,,,,,,Shreeraj Jadhav: Stony Brook University; Gaofeng Deng: Stony Brook University; Marlene Zawin: Stony Brook Medicine; Arie Kaufman: Stony Brook University,dgaofeng@cs.stonybrook.edu; marlene.zawin@stonybrookmedicine.edu; ari@cs.stonybrook.edu
Applications,1209,CoUX: Collaborative Visual Analysis of Think-Aloud Usability Test Videos for Digital Interfaces,"Reviewing a think-aloud video is both time-consuming and demanding as it requires UX (user experience) professionals to attend to many behavioral signals of the user in the video.  Moreover, challenges arise when multiple UX professionals need to collaborate to reduce bias and errors. We propose a collaborative visual analytics tool, CoUX, to facilitate UX evaluators collectively reviewing think-aloud usability test videos of digital interfaces. CoUX seamlessly supports usability problem identification, annotation, and discussion in an integrated environment. To ease the discovery of usability problems, CoUX visualizes a set of problem-indicators based on acoustic, textual, and visual features extracted from the video and audio of a think-aloud session with machine learning.CoUX further enables collaboration amongst UX evaluators for logging, commenting, and consolidating the discovered problems with a chatbox-like user interface. We designed CoUX based on a formative study with two UX experts and insights derived from the literature. We conducted a user study with six pairs of UX practitioners on collaborative think-aloud video analysis tasks. The results indicate that CoUX is useful and effective in facilitating both problem identification and collaborative teamwork. We provide insights into how different features of CoUX were used to support both independent analysis and collaboration. Furthermore, our work highlights opportunities to improve collaborative usability test video analysis.","User experience, usability problems, think-aloud, video analysis, machine learning, visual analytics, collaboration",Ehsan,Jahangirzadeh Soure,Emily,Kuang,Mingming,Fan,Jian,Zhao,,,,,,,,,,,,,,,,,,,Ehsan Jahangirzadeh Soure: University of Waterloo; Emily Kuang: Rochester Institute of Technology; Mingming Fan: Rochester Institute of Technology; Jian Zhao: University of Waterloo,emilykuang6@hotmail.com; mingming.fan@rit.edu; jianzhao@uwaterloo.ca
Applications,1211,MiningVis: Visual Analytics of the Bitcoin Mining Economy,"We present a visual analytics tool, MiningVis, to explore the long-term historical evolution and dynamics of the Bitcoin mining ecosystem. Bitcoin is a cryptocurrency that attracts much attention but remains difficult to understand. Particularly important to the success, stability, and security of Bitcoin is a component of the system called ""mining.'' Miners are responsible for validating transactions and are incentivized to participate by the promise of a monetary reward. Mining pools have emerged as collectives of miners that ensure a more stable and predictable income. MiningVis aims to help analysts understand the evolution and dynamics of the Bitcoin mining ecosystem, including mining market statistics, multi-measure mining pool rankings, and pool hopping behavior. Each of these features can be compared to external data concerning pool characteristics and Bitcoin news. In order to assess the value of MiningVis, we conducted online interviews and insight-based user studies with Bitcoin miners. We describe research questions tackled and insights made by our participants and illustrate practical implications for visual analytics systems for Bitcoin mining.","Visual analytics, Bitcoin, Bitcoin mining, mining pools, pool hopping",Natkamon,Tovanich,Nicolas,Soulié,Nicolas,Heulot,Petra,Isenberg,,,,,,,,,,,,,,,,,,,"Natkamon Tovanich: IRT SystemX; Nicolas Soulié: Université Paris-Saclay, Univ Evry, IMT-BS, LITEM; Nicolas Heulot: IRT SystemX; Petra Isenberg: Université Paris-Saclay, CNRS, Inria, LISN",nicolas.soulie@imt-bs.eu; nicolas.heulot@irt-systemx.fr; petra.isenberg@inria.fr
Analytics & Decisions,1212,Gender in 30 Years of IEEE Visualization,"We present an exploratory analysis of gender representation among the authors, committee members, and award winners at the IEEE Visualization (VIS) conference over the last 30 years. Our goal is to provide descriptive data on which diversity discussions and efforts in the community can build. We look in particular at the gender of VIS authors as a proxy for the community at large. We consider measures of overall gender representation among authors, differences in careers, positions in author lists, and collaborations. We found that the proportion of female authors has increased from 9% in the first five years to 22% in the last five years of the conference. Over the years, we found the same representation of women in program committees and slightly more women in organizing committees. Women are less likely to appear in the last author position, but more in the middle positions. In terms of collaboration patterns, female authors tend to collaborate more than expected with other women in the community. All non-gender related data is available on https://osf.io/ydfj4/ and the gender-author matching can be accessed through https://nyu.databrary.org/volume/1301.","visualization, gender, diversity, publication, scientometry, collaboration",Natkamon,Tovanich,Pierre,Dragicevic,Petra,Isenberg,,,,,,,,,,,,,,,,,,,,,"Natkamon Tovanich: IRT SystemX; Pierre Dragicevic: Université Paris-Saclay, CNRS, Inria, LISN; Petra Isenberg: Université Paris-Saclay, CNRS, Inria, LISN",pierre.dragice@gmail.com; petra.isenberg@inria.fr
Analytics & Decisions,1218,VideoModerator: A Risk-aware Framework for Multimodal Video Moderation in E-Commerce,"Video moderation, which refers to remove deviant or explicit content from e-commerce livestreams, has become prevalent owing to social and engaging features. However, this task is tedious and time consuming due to the difficulties associated with watching and reviewing multimodal video content, including video frames and audio clips. To ensure effective video moderation, we propose VideoModerator, a risk-aware framework that seamlessly integrates human knowledge with machine insights. This framework incorporates a set of advanced machine learning models to extract the risk-aware features from multimodal video content and discover potentially deviant videos. Moreover, this framework introduces an interactive visualization interface with three views, namely, a video view, a frame view, and an audio view. In the video view, we adopt a segmented timeline and highlight high-risk periods that may contain deviant information. In the frame view, we present a novel visual summarization method that combines risk-aware features and video context to enable quick video navigation. In the audio view, we employ a storyline-based design to provide a multi-faceted overview which can be used to explore audio content. Furthermore, we report the usage of VideoModerator through a case scenario and conduct experiments and a controlled user study to validate its effectiveness.","video moderation, video visualization, e-commerce livestreaming",Tan,Tang,Yanhong,Wu,Lingyun,Yu,Yuhong,Li,Yingcai,Wu,,,,,,,,,,,,,,,,,Tan Tang: Zhejiang University; Yanhong Wu: Zhejiang University; Lingyun Yu: Xi'an Jiaotong-Liverpool University; Yuhong Li: Alibaba Group; Yingcai Wu: Zhejiang University,yanhongwu@zju.edu.cn; lingyun.yu@xjtlu.edu.cn; daniel.lyh@alibaba-inc.com; ycwu@zju.edu.cn
Theoretical & Empirical,1219,An Automated Approach to Reasoning About Task-Oriented Visualization Insights in Responsive Visualization,"Authors often transform a large screen visualization for smaller displays through rescaling, aggregation and other techniques when creating visualizations for both desktop and mobile devices (i.e., responsive visualization). However, transformations can alter relationships or patterns implied by the large screen view, requiring authors to reason carefully about what information to preserve while adjusting their design for the smaller display. We propose an automated approach to approximating the loss of support for task-oriented visualization insights (identification, comparison, and trend) in responsive transformation of a source visualization. We operationalize identification, comparison, and trend loss as objective functions calculated by comparing properties of the rendered source visualization to each realized target (small screen) visualization. To evaluate the utility of our approach, we train machine learning models on human ranked small screen alternative visualizations across a set of source visualizations. We find that our approach achieves an accuracy of 84% (random forest model) in ranking visualizations. We demonstrate this approach in a prototype responsive visualization recommender that enumerates responsive transformations using Answer Set Programming and evaluates the preservation of task-oriented insights using our loss measures. We discuss implications of our approach for the development of automated and semi-automated responsive visualization recommendation.","Task-oriented insight preservation, responsive visualization",Hyeok,Kim,Ryan,Rossi,Abhraneel,Sarma,Dominik,Moritz,Jessica,Hullman,,,,,,,,,,,,,,,,,Hyeok Kim: Northwestern University; Ryan Rossi: Adobe Research; Abhraneel Sarma: Northwestern University; Dominik Moritz: Carnegie Mellon University; Jessica Hullman: Northwestern University,ryrossi@adobe.com; abhraneelsarma2024@u.northwestern.edu; domoritz@cmu.edu; jhullman@northwestern.edu
Representations & Interaction,1220,Network Hypothetical Outcome Plots for Visualizing Uncertainty in Probabilistic Network Data,"Probabilistic networks are challenging to visualize using the traditional node-link diagram. Encoding edge probability using visual variables like width or fuzziness makes it difﬁcult for users of static network visualizations to estimate network statistics like densities, isolates, path lengths, or clustering under uncertainty. We introduce Network Hypothetical Outcome Plots (NetHOPs), a visualization technique that animates a sequence of network realizations sampled from a network distribution deﬁned by probabilistic edges. NetHOPs employ an aggregation and anchoring algorithm used in dynamic and longitudinal graph drawing to parameterize layout stability to support uncertainty estimation. We present a community matching algorithm we developed to enable visualizing the uncertainty of cluster membership and community occurrence. We describe the results of a study in which 51 network experts used NetHOPs to complete a set of common visual analysis tasks and reported how they perceived network structures and properties subject to uncertainty. Participants’ estimates fell, on average, within 11% of the ground truth statistics, suggesting NetHOPs can be a reasonable approach for enabling network analysts to reason about multiple properties under uncertainty. Participants appeared able to articulate the distribution of network statistics slightly more accurately when they could manipulate the layout anchoring and the animation speed. Based on these ﬁndings, we synthesize design recommendations for developing and using animated network visualizations for probabilistic networks.","Network, Uncertainty, Application",Dongping,Zhang,Eytan,Adar,Jessica,Hullman,,,,,,,,,,,,,,,,,,,,,Dongping Zhang: Northwestern University; Eytan Adar: University of Michigan; Jessica Hullman: Northwestern University,eadar@umich.edu; jhullman@northwestern.edu
Theoretical & Empirical,1224,Untidy data: The Unreasonable Effectiveness of Tables,"Working with data in table form is usually considered a preparatory and tedious step in the sensemaking pipeline; a way of getting the data ready for more sophisticated visualization and analytical tools. But for many people, spreadsheets — the quintessential table tool — remain a critical part of their information ecosystem, allowing them to interact with their data in ways that are hidden or abstracted in more complex tools. This is particularly true for data workers [61], people who work with data as part of their job but do not identify as professional analysts or data scientists. We report on a qualitative study of how these workers interact with and reason about their data. Our findings show that data tables serve a broader purpose beyond data cleanup at the initial stage of a linear analytic flow: users want to see and “get their hands on” the underlying data throughout the analytics process, reshaping and augmenting it to support sensemaking. They reorganize, mark up, layer on levels of detail, and spawn alternatives within the context of the base data. These direct interactions and human-readable table representations form a rich and cognitively important part of building understanding of what the data mean and what they can do with it. We argue that interactive tables are an important visualization idiom in their own right; that the direct data interaction they afford offers a fertile design space for visual analytics; and that sense making can be enriched by more flexible human-data interaction than is currently supported in visual analytics tools.","Data practices, Tabular data, Interview study, Visualization, Analytics, Data workers, Sensemaking.",Lyn,Bartram,Michael,Correll,Melanie,Tory,,,,,,,,,,,,,,,,,,,,,Lyn Bartram: Simon Fraser University; Michael Correll: Tableau Software; Melanie Tory: Northeastern University,mcorrell@tableau.com; m.tory@northeastern.edu
Applications,1226,Seek for Success: A Visualization Approach for Understanding the Dynamics of Academic Careers,"Abstract— How to achieve academic career success has been a long-standing research question in social science research. With the growing availability of large-scale well-documented academic profiles and career trajectories, scholarly interest in career success has been reinvigorated, which has emerged to be an active research domain called the Science of Science (i.e., SciSci). In this study, we adopt an innovative dynamic perspective to examine how individual and social factors will influence career success over time. We propose ACSeeker, an interactive visual analytics approach to explore the potential factors of success and how the influence of multiple factors changes at different stages of academic careers. We first applied a Multi-factor Impact Analysis framework to estimate the effect of different factors on academic career success over time. We then developed a visual analytics system to understand the dynamic effects interactively. A novel timeline is designed to reveal and compare the factor impacts based on the whole population. A customized career line showing the individual career development is provided to allow a detailed inspection. To validate the effectiveness and usability of ACSeeker, we report two case studies and interviews with a social scientist and general researchers.","Career Analysis, Academic Profiles, Science of Science, Publication Data, Citation Data, Sequence Analysis",Yifang,Wang,Tai-Quan,Peng,Huihua,Lu,Haoren,Wang,Xiao,Xie,Huamin,Qu,Yingcai,Wu,,,,,,,,,,,,,Yifang Wang: The Hong Kong University of Science and Technology; Tai-Quan Peng: Michigan State University; Huihua Lu: Zhejiang University; Haoren Wang: Zhejiang University; Xiao Xie: Zhejiang University; Huamin Qu: The Hong Kong University of Science and Technology; Yingcai Wu: Zhejiang University,pengtaiq@msu.edu; huihualu@zju.edu.cn; haorenwang@zju.edu.cn; xxie@zju.edu.cn; huamin@cse.ust.hk; ycwu@zju.edu.cn
Representations & Interaction,1271,Loon: Using Exemplars to Visualize Large Scale Microscopy Data,"Which drug is most promising for a cancer patient? This is a question a new microscopy-based approach for measuring the mass of individual cancer cells treated with different drugs promises to answer in only a few hours. However, the analysis pipeline for extracting data from these images is still far from complete automation: human intervention is necessary for quality control for preprocessing steps such as segmentation, to adjust filters, and remove noise, and for the analysis of the result. To address this workflow, we developed Loon, a visualization tool for analyzing drug screening data based on quantitative phase microscopy imaging. Loon visualizes both derived data such as growth rates, and imaging data. Since the images are collected automatically at a large scale, manual inspection of images and segmentations is infeasible. However, reviewing representative samples of cells is essential, both for quality control and for data analysis. We introduce a new approach of choosing and visualizing representative exemplar cells that retain a close connection to the low-level data. By tightly integrating the derived data visualization capabilities with the novel exemplar visualization and providing selection and filtering capabilities, Loon is well suited for making decisions about which drugs are suitable for a specific patient.","Microscopy Visualization, Cancer Cell Lines, Exemplars, Design Study.",Devin,Lange,Eddie,Polanco,Robert,Judson-Torres,Thomas,Zangle,Alexander,Lex,,,,,,,,,,,,,,,,,Devin Lange: University of Utah; Eddie Polanco: University of Utah; Robert L Judson-Torres: University of Utah; Thomas A Zangle: University of Utah; Alexander Lex: University of Utah,eddiepolanco@chemeng.utah.edu; robert.judson-torres@hci.utah.edu; tzangle@chemeng.utah.edu; alex@sci.utah.edu
Analytics & Decisions,1272,Neo: Generalizing Confusion Matrix Visualization to Hierarchical and Multi-Output Labels,"The confusion matrix, a ubiquitous visualization for helping people evaluate machine learning models, is a tabular layout that compares predicted class labels against actual class labels over all data instances. We conduct formative research with machine learning practitioners at a large technology company and find that conventional confusion matrices do not support more complex data-structures found in modern-day applications, such as hierarchical and multi-output labels. To express such variations of confusion matrices, we design an algebra that models confusion matrices as probability distributions. Based on this algebra, we develop Neo, a visual analytics system that enables practitioners to flexibly author and interact with hierarchical and multi-output confusion matrices, visualize derived metrics, renormalize confusions, and share matrix specifications. Finally, we demonstrate Neo's utility with three case studies that help people better understand model performance and reveal hidden confusions.","Confusion matrices, model evaluation, visual analytics, machine learning, interactive systems",Jochen,Görtler,Fred,Hohman,Dominik,Moritz,Kanit,Wongsuphasawat,Donghao,Ren,Rahul,Nair,,,,,,,,,,,,,,,Jochen Görtler: University of Konstanz; Fred Hohman: Apple; Dominik Moritz: Apple; Kanit Wongsuphasawat: Apple; Donghao Ren: Apple; Rahul Nair: Apple,jochen.goertler@uni-konstanz.de; domoritz@cmu.edu; kanitw@gmail.com; donghao@apple.com; rahul_nair@apple.com
Systems & Rendering,1274,Gosling: A Grammar-based Toolkit for Scalable and Interactive Genomics Data Visualization,"The combination of diverse data types and analysis tasks in genomics has resulted in the development of a wide range of visualization techniques and tools. However, most existing tools are tailored to a specific problem or data type and offer limited customization, making it challenging to optimize visualizations for new analysis tasks or datasets. To address this challenge, we designed Gosling—a grammar for interactive and scalable genomics data visualization. Gosling balances expressiveness for comprehensive multi-scale genomics data visualizations with accessibility for domain scientists. Our accompanying JavaScript toolkit called Gosling.js provides scalable and interactive rendering. Gosling.js is built on top of an existing platform for web-based genomics data visualization to further simplify the visualization of common genomics data formats. We demonstrate the expressiveness of the grammar through a variety of real-world examples. Furthermore, we show how Gosling supports the design of novel genomics visualizations. An online editor and examples of Gosling.js, its source code, and documentation are available at https://gosling.js.org.","Genomics, declarative specification, visualization grammar",Sehi,L'Yi,Qianwen,Wang,Fritz,Lekschas,Nils,Gehlenborg,,,,,,,,,,,,,,,,,,,Sehi L'Yi: Harvard Medical School; Qianwen Wang: Harvard Medical School; Fritz Lekschas: Harvard University; Nils Gehlenborg: Harvard Medical School,qianwen_wang@hms.harvard.edu; lekschas@seas.harvard.edu; nils@hms.harvard.edu
Systems & Rendering,1275,DIEL: Interactive Visualization Beyond the Here and Now,"Interactive visualization design and research have primarily focused on local data and synchronous events. However, for more complex use cases—e.g., remote database access and streaming data sources—developers must grapple with distributed data and asynchronous events. Currently, constructing these use cases is difficult and time-consuming; developers are forced to operationally program low-level details like asynchronous database querying and reactive event handling. This approach is in stark contrast to modern methods for browser-based interactive visualization, which feature high-level declarative specifications. In response, we present DIEL, a declarative framework that supports asynchronous events over distributed data. Like many declarative visualization languages, DIEL developers need only specify what data they want, rather than procedural steps for how to assemble it; uniquely, DIEL models asynchronous events (e.g., user interactions or server responses) as streams of data that are captured in event logs. To specify the state of a user interface at any time, developers author declarative queries over the data and event logs; DIEL compiles and optimizes a corresponding dataflow graph, and synthesizes necessary low-level distributed systems details. We demonstrate DIEL’s performance and expressivity through ex-ample interactive visualizations that make diverse use of remote data and coordination of asynchronous events. We further evaluate DIEL’s usability using the Cognitive Dimensions of Notations framework, revealing wins such as ease of change, and compromises such as premature commitments.","Interactive Visualization Toolkit/Library, Scalability, Asynchrony",Yifan,Wu,Remco,Chang,Joseph,Hellerstein,Arvind,Satyanarayan,eugene,Wu,,,,,,,,,,,,,,,,,Yifan Wu: UC Berkeley; Remco Chang: Tufts University; Joseph Hellerstein: UC Berkeley; Arvind Satyanarayan: MIT; eugene Wu: Columbia University,remco@cs.tufts.edu; hellerstein@berkeley.edu; arvindsatya@mit.edu; ewu@cs.columbia.edu
Analytics & Decisions,1284,"VBridge: Connecting the Dots Between Features, Explanations, and Data for Healthcare Models","Machine learning (ML) is increasingly applied to Electronic Health Records (EHRs) to solve clinical prediction tasks. Although many ML models perform promisingly, issues with model transparency and interpretability limit their adoption in clinical practice. Directly using existing explainable ML techniques in clinical settings can be challenging. Through literature surveys and collaborations with six clinicians with an average of 17 years of clinical experience, we identified three key challenges, including clinicians' unfamiliarity with ML features, lack of contextual information, and the need for cohort-level evidence. Following an iterative design process, we further designed and developed VBridge, a visual analytics tool that seamlessly incorporates ML explanations into clinicians' decision-making workflow. The system includes a novel hierarchical display of contribution-based feature explanations and enriched interactions that connect the dots between ML features, explanations, and data. We demonstrated the effectiveness of VBridge through two case studies and expert interviews with four clinicians, showing that visually associating model explanations with patients' situational records can help clinicians better interpret and use model predictions when making clinician decisions. We further derived a list of design implications for developing future explainable ML tools to support clinical decision-making.","Explainable Artificial Intelligence, Healthcare, Visual Analytics, Decision Making",Furui,Cheng,Dongyu,Liu,Fan,Du,Yanna,Lin,Alexandra,Zytek,Haomin,Li,Huamin,Qu,Kalyan,Veeramachaneni,,,,,,,,,,,"Furui Cheng: The Hong Kong University of Science and Technology; Dongyu Liu: MIT; Fan Du: Adobe Research; Yanna Lin: Hong Kong University of Science and Technology; Alexandra Zytek: MIT; Haomin Li: Children's hospital, Zhejiang university; Huamin Qu: The Hong Kong University of Science and Technology; Kalyan Veeramachaneni: MIT",ustdongyu@gmail.com; fdu@adobe.com; ylindg@connect.ust.hk; zyteka@mit.edu; hmli@zju.edu.cn; huamin@cse.ust.hk; kalyanv@mit.edu
Systems & Rendering,1286,VizFixer: A Linter and Fixer Framework for Data Visualization,"Despite the rising popularity of automated visualization tools, existing systems tend to provide direct results which do not always fit the input data or meet visualization requirements. Therefore, additional specification adjustments are still required in real-world use cases. However, manual adjustments are difficult since most users do not necessarily possess adequate skills or visualization knowledge. Even experienced users might create imperfect visualizations that involve chart construction errors. We present a framework, VizFixer, to help users detect flaws and rectify already-built but defective visualizations. The framework consists of two components, (1) a visualization linter, which applies well-recognized principles to inspect the legitimacy of rendered visualizations, and (2) a visualization fixer, which automatically corrects the detected violations according to the linter. We implement the framework into an online editor prototype based on Vega-Lite specifications. To further evaluate the system, we conduct an in-lab user study. The results prove its effectiveness and efficiency in identifying and fixing errors for data visualizations.","Visualization Linting, Automated Visualization Design, Visualization Optimization",Qing,Chen,Fuling,Sun,Xinyue,Xu,Zui,Chen,Jiazhe,Wang,Nan,Cao,,,,,,,,,,,,,,,Qing Chen: Tongji University; Fuling Sun: Tongji University; Xinyue Xu: Tongji University; Zui Chen: Tongji University; Jiazhe Wang: Ant Group; Nan Cao: Tongji College of Design and Innovation,fulingsun.idvx@gmail.com; xxy.ai@outlook.com; zuic10a@gmail.com; neoddish@outlook.com; nan.cao@gmail.com
Applications,1287,EVis: Visually Analyzing Environmentally Driven Events,"Earth scientists are increasingly employing time series data with multiple dimensions and high temporal resolution to study the impacts of climate and environmental changes on Earth’s atmosphere, biosphere, hydrosphere, and lithosphere. However, the large number of variables and varying time scales of antecedent conditions contributing to natural phenomena hinder scientists from completing more than the most basic analyses. In this paper, we present EVis (Environmental Visualization), a new visual analytics prototype to help scientists analyze and explore recurring environmental events (e.g. rock fracture, landslides, heat waves, floods) and their relationships with high dimensional time series of continuous numeric environmental variables, such as ambient temperature and precipitation. EVis provides coordinated scatterplots, heatmaps, histograms, and RadViz for foundational analyses. These features allow users to interactively examine relationships between events and one, two, three, or more environmental variables. EVis also provides a novel visual analytics approach to allowing users to discover temporally lagging relationships related to antecedent conditions between events and multiple variables, a critical task in Earth sciences. In particular, this latter approach projects multivariate time series onto trajectories in a 2D space using RadViz, and clusters the trajectories for temporal pattern discovery. Our case studies with rock cracking data and interviews with domain experts from a range of sub-disciplines within Earth sciences illustrate the extensive applicability and usefulness of EVis.","Multivariate Time Series, RadViz, Event Data, Visual Analytics, Earth Sciences",Tinghao,Feng,Jing,Yang,Martha-Cary,Eppes,Zhaocong,Yang,Faye,Moser,,,,,,,,,,,,,,,,,Tinghao Feng: UNCC; Jing Yang: UNCC; Martha-Cary Eppes: UNC Charlotte; Zhaocong Yang: UNCC; Faye L Moser: UNC Charlotte,jing.yang@uncc.edu; meppes@uncc.edu; zyang19@uncc.edu; fvisco@uncc.edu
Representations & Interaction,1293,SightBi: Exploring Cross-View Data Relationships with Biclusters,"Multiple-view visualization (MV) has been heavily used in visual analysis tools for sensemaking of data in various domains (e.g., bioinformatics, cybersecurity and text analytics). One common task of visual analysis with multiple views is to relate data across different views. For example, to identify threats, an intelligence analyst needs to link people from a social network graph with locations on a crime-map, and then search and read relevant documents. Currently, exploring cross-view data relationships heavily relies on view-coordination techniques (e.g., brushing and linking). They may require significant user effort on many trial-and-error attempts, such as repetitiously selecting elements in one view, observing and following elements highlighted in other views. To address this, we present SightBi, a visual analytics approach for supporting cross-view data relationship explorations. We discuss the design rationale of SightBi in detail, with identified user tasks regarding the usage of cross-view data relationships. SightBi formalize cross-view data relationships as biclusters and compute them from a dataset. SightBi uses a bi-context design that highlights creating stand-alone relationship-views. This helps to preserve existing views and serves as an overview of cross-view data relationships to guide user explorations. Moreover, SightBi allows users to interactively manage the layout of multiple views by using newly created relationship-views. With a usage scenario, we demonstrate the usefulness of SightBi for sensemaking of cross-view data relationships.","Cross-view data relationship, multi-view visualization, bicluster, visual analytics",Maoyuan,Sun,Abdul Rahman,Shaikh,Hamed,Alhoori,Jian,Zhao,,,,,,,,,,,,,,,,,,,Maoyuan Sun: Northern Illinois University; Abdul Rahman Shaikh: Northern Illinois University ; Hamed Alhoori: Northern Illinois University ; Jian Zhao: University of Waterloo,sabdulrahman095@gmail.com; alhoori@niu.edu; jianzhao@uwaterloo.ca
Representations & Interaction,1301,A Design Space for Applying the Freytag’s Pyramid Structure to Data Stories,"Data stories integrate compelling visual content to communicate data insights in the form of narratives. The narrative structure of a data story serves as the backbone that determines its expressiveness, and it can largely influence how audiences perceive the insights. Freytag's Pyramid is a classic narrative structure that has been widely used in film and literature. While there are continuous recommendations and discussions about applying Freytag's Pyramid to data stories, there is little systematic and practical guidance for data story creators on how to use Freytag's Pyramid for structured data story creation. To bridge this gap, we examined how existing practices apply Freytag's Pyramid through analyzing stories extracted from 103 data videos. Based on our findings, we propose a design space of narrative patterns, data flows, and visual communications to provide practical guidance on achieving narrative intents, organizing data facts, and selecting visual design techniques through the story creation process. We evaluated the proposed design space through a workshop with 25 participants. The results show that our design space provides a clear framework for rapid storyboarding of data stories with Freytag's Pyramid.","Freytag's Pyramid, Narrative Structure, Data-driven Storytelling, Design Space",Leni,Yang,Xian,XU,Xingyu,Lan,Ziyan,Liu,Shunan,Guo,Yang,Shi,Huamin,Qu,Nan,Cao,,,,,,,,,,,Leni Yang: The Hong Kong University of Science and Technology; Xian XU: The Hong Kong University of Science and Technology; Xingyu Lan: Tongji University; Ziyan Liu: Design &Innovation; Shunan Guo: Adobe Research; Yang Shi: Tongji University; Huamin Qu: The Hong Kong University of Science and Technology; Nan Cao: Tongji College of Design and Innovation,xxubq@connect.ust.hk; xingyulan@tongji.edu.cn; 1533130092@qq.com; g.shunan@gmail.com; shiyang1230@gmail.com; huamin@cse.ust.hk; nan.cao@gmail.com
Analytics & Decisions,1308,Knowledge Rocks: Adding Knowledge Assistance to Visualization Systems,"We present Knowledge Rocks, an implementation strategy and guideline for augmenting visualization systems to knowledge-assisted visualization systems, as defined by the KAVA model. Visualization systems become more and more sophisticated. Hence, it is increasingly important to support users with an integrated knowledge base in making constructive choices and drawing the right conclusions. We support the effective reactivation of visualization software resources by augmenting them with knowledge-assistance. To provide a general and yet supportive implementation strategy, we propose an implementation process that bases on an application-agnostic architecture. This architecture is derived from existing knowledge-assisted visualization systems and the KAVA model. Its centerpiece is an ontology that is able to automatically analyze and classify input data, linked to a database to store classified instances. We discuss design decisions and advantages of the KR framework and illustrate its broad area of application in diverse integration possibilities of this architecture into an existing visualization system. In addition, we provide a detailed case study by augmenting an it-security system with knowledge-assistance facilities.","Knowledge-Assisted Visualization, Ontology, IT-Security",Anna-Pia,Lohfink,Simon,Duque Anton,Heike,Leitte,Christoph,Garth,,,,,,,,,,,,,,,,,,,Anna-Pia Lohfink: Technische Universität Kaiserslautern; Simon D Duque Anton: German Research Center for Artificial Intelligence; Heike Leitte: TU Kaiserslautern; Christoph Garth: Technische Universität Kaiserslautern,simon.duque_anton@dfki.de; leitte@cs.uni-kl.de; garth@cs.uni-kl.de
Systems & Rendering,1310,Rapid Labels: Point-Feature Labeling on GPU,"Labels, short textual annotations are an important component of data visualizations, illustrations, infographics, and geographical maps. In interactive applications, the labeling method responsible for positioning the labels should not take the resources from the application itself. In other words, the labeling method should provide the result as fast as possible. In this work, we propose a greedy point-feature labeling method running on GPU. In contrast to existing methods that position the labels sequentially, the proposed method positions several labels in parallel. Yet, we guarantee that the positioned labels will not overlap, nor will they overlap important visual features. When the proposed method is searching for the label position of a point-feature, the available label candidates are evaluated with respect to overlaps with important visual features, conflicts with label candidates of other point-features, and their ambiguity. The evaluation of each label candidate is done in constant time independently from the number of point-features, the number of important visual features, and the resolution of the created image. Our measurements indicate that the proposed method is able to position more labels than existing greedy methods that do not evaluate conflicts between the label candidates. At the same time, the proposed method achieves a significant increase in performance. The increase in performance is mainly due to the parallelization and the efficient evaluation of label candidates.","Label placement, Point-feature labeling, GPU.",Václav,Pavlovec,Ladislav,Čmolík,,,,,,,,,,,,,,,,,,,,,,,Václav Pavlovec: CTU in Prague; Ladislav Čmolík: CTU in Prague,cmolikl@fel.cvut.cz
Theoretical & Empirical,1314,Context Matters: A Theory of Semantic Discriminability for Perceptual Encoding Systems,"People’s associations between colors and concepts influence their ability to interpret the meanings of colors in information visualizations. Previous work has suggested such effects are limited to concepts that have strong, specific associations with colors. However, although a concept may not be strongly associated with any colors, its mapping can be disambiguated in the context of other concepts in an encoding system. We articulate this view in Semantic Discriminability Theory, a general framework for understanding conditions determining when people can infer meaning from perceptual features. Semantic discriminability is the degree to which observers can infer a unique mapping between visual features and concepts. Semantic Discriminability Theory posits that the capacity for semantic discriminability for a set of concepts is constrained by the difference between the feature-concept association distributions across the concepts in the set. We define formal properties of this theory, and test its implications in two experiments. The results show that the capacity to produce semantically discriminable colors for sets of concepts was indeed constrained by the statistical distance between color-concept association distributions (Experiment 1). Moreover, people could interpret meanings of colors in bar graphs insofar as the colors were semantically discriminable, even for concepts previously deemed “non-colorable” (Experiment 2). The results suggest that colors are more robust for visual communication than previously thought.","Visual Reasoning, Information Visualization, Visual Communication, Visual Encoding, Color Cognition",Kushin,Mukherjee,Brian,Yin,Brianne,Sherman,Laurent,Lessard,Karen,Schloss,,,,,,,,,,,,,,,,,"Kushin Mukherjee: University of Wisconsin-Madison; Brian N. Yin: University of California, Berkeley; Brianne E Sherman: University of Wisconsin - Madison; Laurent Lessard: Northeastern University; Karen Schloss: University of Wisconsin-Madison",brianyin99@gmail.com; besherman2@wisc.edu; laurent.lessard@wisc.edu; kschloss@wisc.edu
Applications,1316,Explanatory journeys: visualising to understand and explain administrative justice paths of redress,"Administrative justice concerns the relationships between individuals and the state. It includes redress and complaints on decisions of a child’s education, social care, licensing, planning, environment, housing and homelessness. However, if someone has a complaint or an issue, it is challenging for people to understand different possible redress paths and explore what path is suitable for their situation. Explanatory visualisation has the potential to display these paths of redress in a clear way, such that people can see, understand and explore their options. The visualisation challenge is further complicated because information is spread across many documents, laws, guidance and policies and requires judicial interpretation. Consequently, there is not a single database of paths of redress. In this work we present how we have co-designed a system to visualise administrative justice paths of redress. Simultaneously, we classify, collate and organise the underpinning data, from expert workshops, heuristic evaluation and expert critical reflection. We make four contributions: (i) an application design study of the explanatory visualisation tool (Artemus), (ii) coordinated and co-design approach to aggregating the data, (iii) two in-depth case studies in housing and education demonstrating explanatory paths of redress in administrative law, and (iv) reflections on the expert co-design process and expert data gathering and explanatory visualisation for administrative justice and law.","Explanatory visualisation, administrative justice, law, law visualisation",Jonathan,Roberts,Peter,Butcher,Ann,Sherlock,Sarah,Nason,,,,,,,,,,,,,,,,,,,Jonathan C Roberts: Bangor University; Peter W. S. Butcher: Bangor University; Ann Sherlock: Bangor University; Sarah Nason: Bangor University,p.butcher@chester.ac.uk; gellifawrann@gmail.com; s.nason@bangor.ac.uk
Applications,1320,LoopGrafter: Visual Support for the Grafting Workflow of Protein Loops,"In the process of understanding and redesigning the function of proteins in modern biochemistry, protein engineers are increasingly focusing on the exploration of regions in proteins called loops. Analyzing various characteristics of these regions helps the experts to design the transfer of the desired function from one protein to another. This process is denoted as loop grafting. As this process requires extensive manual treatment and currently there is no proper visual support for it, we designed LoopGrafter: a web-based tool that provides experts with visual support through all the loop grafting pipeline steps. The tool is logically divided into several phases, starting with the definition of two input proteins and ending with a set of grafted proteins. Each phase is supported by a specific set of abstracted 2D visual representations of loaded proteins and their loops that are interactively linked with the 3D view onto proteins. By sequentially passing through the individual phases, the user is shaping the list of loops that are potential candidates for loop grafting. In the end, the actual in-silico insertion of the loop candidates from one protein to the other is performed and the results are visually presented to the user. In this way, the fully computational rational design of proteins and their loops results in newly designed protein structures that can be further assembled and tested through in-vitro experiments. LoopGrafter was designed in tight collaboration with protein engineers, and its final appearance reflects many testing iterations. We showcase the contribution of LoopGrafter on a real case scenario and provide the readers with the experts' feedback, confirming the usefulness of our tool.","Protein visualization, protein engineering, loop grafting, abstracted views",Filip,Opálený,Pavol,Ulbrich,Joan,Planas-Iglesias,Jan,Byška,Gaspar,Pinto,David,Bednář,Katarína,Furmanová,Barbora,Kozlikova,,,,,,,,,,,"Filip Opálený: Faculty of Informatics, Masaryk University; Pavol Ulbrich: Faculty of Informatics, Masaryk University; Joan Planas-Iglesias: Faculty of Science, Masaryk University; Jan Byška: Faculty of Informatics, Masaryk University; Gaspar P Pinto: Faculty of Science, Masaryk University; David Bednář: Faculty of Science, Masaryk University; Katarína Furmanová: Faculty of Informatics, Masaryk University; Barbora Kozlikova: Masaryk University",paloulbrich@gmail.com; joan.planas@mail.muni.cz; xbyska@fi.muni.cz; gaspar.pinto@fnusa.cz; 222755@mail.muni.cz; katarina.furmanova@gmail.com; kozlikova@fi.muni.cz
Theoretical & Empirical,1334,"Learning Objectives, Insights, and Assessments: How Specification Formats Impact Design","Despite the ubiquity of communicative visualizations, specifying communicative intent during design is ad hoc. Whether we are selecting from a set of visualizations, commissioning someone to produce them, or creating them ourselves, an effective way of specifying intent can help guide this process. Ideally, we would have a concise and shared specification language. In previous work, we have argued that communicative intents can be viewed as a learning/assessment problem (i.e., what should the reader learn and what test should they do well on). Learning-based specification formats are linked (e.g., assessments are derived from objectives) but some may more effectively specify communicative intent. Through a large-scale experiment, we studied three specification types: learning objectives, insights, and assessments. Participants, guided by one of these specifications, rated their preferences for a set of visualization designs. Then, we evaluated the set of visualization designs to assess which specification led participants to prefer the most effective visualizations. We find that while all specification types have benefits over no-specification, each format has its own advantages. Our results show that learning objective-based specifications helped participants the most in visualization selection. We also identify situations in which specifications may be insufficient and assessments are vital.","Communicative visualization, evaluation, visualization specification.",Elsie,Lee,Shiqing,He,Eytan,Adar,,,,,,,,,,,,,,,,,,,,,Elsie Lee: University of Michigan; Shiqing He: University of Michigan; Eytan Adar: University of Michigan,heslicia@umich.edu; eadar@umich.edu
Data Transformations,1336,Pyramid-based Scatterplots Sampling for Progressive and Streaming Data Visualization,"We present a pyramid-based scatterplot sampling technique to avoid overplotting and enable progressive and streaming
visualization of large data. Our technique is based on a multiresolution pyramid-based decomposition of the underlying density map
and makes use of the density values in the pyramid to guide the sampling at each scale for preserving the relative data densities
and outliers. We show that our technique is competitive in quality with state-of-the-art methods and runs faster by about an order of
magnitude. Also, we have adapted it to deliver progressive and streaming data visualization by processing the data in chunks and
updating the scatterplot areas with visible changes in the density map. A quantitative evaluation shows that our approach generates
stable and faithful progressive samples that are comparable to the state-of-the-art method in preserving relative densities and superior
to it in keeping outliers and stability when switching frames. We present two case studies that demonstrate the effectiveness of our
approach for exploring large data.","Scatterplots, sampling, pyramid, progressive visualization, streaming visualization, scalability, big data",Xin,Chen,Jian,Zhang,Chi-Wing,Fu,Jean-Daniel,Fekete,Yunhai,Wang,,,,,,,,,,,,,,,,,Xin Chen: Shandong Unversity; Jian Zhang: CNIC; Chi-Wing Fu: The Chinese University of Hong Kong; Jean-Daniel Fekete: Inria; Yunhai Wang: Shandong University,chenxin199634@gmail.com; zhangjian@sccas.cn; cwfu@cse.cuhk.edu.hk; jean-daniel.fekete@inria.fr
Theoretical & Empirical,1341,A Critical Reflection on Visualization Research: Where Do Decision Making Tasks Hide?,"It has been widely suggested that a key goal of visualization systems is to assist decision making, but is this true? We conduct a critical investigation on whether the activity of decision making is indeed central to the visualization domain. By approaching decision making as a user task, we explore the degree to which decision tasks are evident in visualization research and user studies. Our analysis suggests that decision tasks are not commonly found in current visualization task taxonomies and that the visualization field has yet to leverage guidance from decision theory domains on how to study such tasks. We further found that the majority of visualizations addressing decision making were not evaluated based on their ability to assist decision tasks. Finally, to help expand the impact of visual analytics in organizational as well as casual decision making activities, we initiate a research agenda on how decision making assistance could be elevated throughout visualization research.","decision making, data, visualization, visual analytics, taxonomies, task",Evanthia,Dimara,John,Stasko,,,,,,,,,,,,,,,,,,,,,,,Evanthia Dimara: Utrecht University; John Stasko: Georgia Institute of Technology,john.stasko@cc.gatech.edu
Data Transformations,1343,An Efficient Dual-Hierarchy tSNE Minimization,"t-distributed Stochastic Neighbour Embedding (t-SNE) has become a standard for exploratory data analysis, as it is capable of revealing clusters even in complex data while requiring minimal user input. While its run-time complexity limited it to small datasets in the past, recent efforts improved upon the expensive similarity computations and the previously quadratic minimization. Nevertheless, t-SNE still has high runtime and memory costs when operating on millions of points. We present a novel method for executing the t-SNE minimization. While our method overall retains a linear runtime complexity, we obtain a significant performance increase in the most expensive part of the minimization. We achieve a significant improvement without a noticeable decrease in accuracy even when targeting a 3D embedding. Our method constructs a pair of spatial hierarchies over the embedding, which are simultaneously traversed to approximate many N-body interactions at once. We demonstrate an efficient GPGPU implementation and evaluate its performance against state-of-the-art methods on a variety of datasets.","High dimensional data, dimensionality reduction, parallel data structures, dual-hierarchy, GPGPU",Mark,van de Ruit,Markus,Billeter,Elmar,Eisemann,,,,,,,,,,,,,,,,,,,,,Mark van de Ruit: Delft University of Technology; Markus Billeter: University of Leeds; Elmar Eisemann: Delft University of Technology,billeter@gmail.com; e.eisemann@tudelft.nl
Systems & Rendering,1346,Simultaneous Matrix Orderings for Graph Collections,"Undirected graphs are frequently used to model phenomena that deal with interacting objects, such as social networks, brain activity and communication networks. The topology of an undirected graph G can be captured by an adjacency matrix; this matrix in turn can be visualized directly to give insight into the graph structure. Which visual patterns appear in such a matrix visualization crucially depends on the ordering of its rows and columns. Formally defining the quality of an ordering and then automatically computing a high-quality ordering are both challenging problems; however, effective heuristics exist and are used in practice.

Often, graphs do not exist in isolation but as part of a collection of graphs on the same set of vertices, for example, brain scans over time or of different people. To visualize such graph collections, we need a single ordering that works well for all matrices simultaneously. The current state-of-the-art solves this problem by taking a (weighted) union over all graphs and applying existing heuristics. However, this union leads to a loss of information, specifically in those parts of the graphs which are different. We propose a collection-aware approach to avoid this loss of information and apply it to two popular heuristic methods: leaf order and barycenter.

The de-facto standard computational quality metrics for matrix ordering capture only block-diagonal patterns (cliques). Instead, we propose to use Moran's I, a spatial auto-correlation metric, which captures the full range of established patterns. Moran's I refines previously proposed stress measures. Furthermore, the popular leaf order method heuristically optimizes a similar measure which further supports the use of Moran's I in this context. An ordering that maximizes Moran's I can be computed via solutions to the Traveling Salesperson Problem (TSP); approximate orderings can be computed more efficiently, using any of the approximation algorithms for metric TSP.

We evaluated our methods for simultaneous orderings on real-world datasets using Moran's I as the quality metric. Our results show that our collection-aware approach matches or improves performance compared to the union approach, depending on the similarity of the graphs in the collection. Specifically, our Moran's I-based collection-aware leaf order implementation consistently outperforms other implementations. Our collection-aware implementations carry no significant additional computational costs.","Matrix ordering, graph visualization, algorithms, quality measures",Nathan,van Beusekom,Wouter,Meulemans,Bettina,Speckmann,,,,,,,,,,,,,,,,,,,,,Nathan van Beusekom: TU Eindhoven; Wouter Meulemans: TU Eindhoven; Bettina Speckmann: TU Eindhoven,w.meulemans@tue.nl; b.speckmann@tue.nl
Representations & Interaction,1349,Semantic Snapping for Guided Multi-View Visualization Design,"Visual information displays are typically composed of multiple visualizations that are used to facilitate an understanding of the underlying data. A common example are dashboards, which are frequently used in domains such as finance, process monitoring and business intelligence. However, users may not be aware of existing guidelines and lack expert design knowledge when composing such multi-view visualizations. In this paper, we present semantic snapping, an approach to help non-expert users design effective multi-view visualizations from sets of pre-existing views. When a particular view is placed on a canvas, it is ""aligned'' with the remaining views--not with respect to its geometric layout, but based on aspects of the visual encoding itself, such as how data dimensions are mapped to channels. Our method uses an on-the-fly procedure to detect and suggest resolutions for conflicting, misleading, or ambiguous designs, as well as to provide suggestions for alternative presentations. With this approach, users can be guided to avoid common pitfalls encountered when composing visualizations. Our provided examples and case studies demonstrate the usefulness and validity of our approach.","Tabular data, guidelines, mixed initiative human-machine analysis,  coordinated and multiple views",Yngve S.,Kristiansen,Laura,Garrison,Stefan,Bruckner,,,,,,,,,,,,,,,,,,,,,Yngve S. Kristiansen: University of Bergen; Laura Garrison: University of Bergen; Stefan Bruckner: University of Bergen,laura.garrison@uib.no; stefan.bruckner@uib.no
Applications,1361,FairRankVis: A Visual Analytics Framework for Exploring Algorithmic Fairness in Graph Mining Models,"Graph mining is an essential component of recommender systems and search engines. Outputs of graph mining models typically provide a ranked list sorted by each item's relevance or utility. However, recent research has identified issues of algorithmic bias in such models, and new graph mining algorithms have been proposed to correct for bias. 
As such, algorithm developers need tools that can help them uncover potential biases in their models while also exploring the impacts of correcting for biases when employing fairness-aware algorithms. In this paper, we present FairRankVis, a visual analytics framework designed to enable the exploration of multi-class bias in graph mining algorithms. We support both group and individual fairness levels of comparison. Our framework is designed to enable model developers to compare multi-class fairness between algorithms (for example, comparing PageRank with a debiased PageRank algorithm) to assess the impacts of algorithmic debiasing with respect to group and individual fairness. We demonstrate our framework through two usage scenarios inspecting algorithmic fairness.","Graph ranking, fairness, visual analytics",Tiankai,Xie,Yuxin,Ma,Jian,Kang,Hanghang,Tong,Ross,Maciejewski,,,,,,,,,,,,,,,,,Tiankai Xie: Arizona State University; Yuxin Ma: Arizona State University; Jian Kang: University of Illinois at Urbana-Champaign; Hanghang Tong Dr.: University of Illinois at Urbana-Champaign; Ross Maciejewski: Arizona State University,yuxinma@asu.edu; jiank2@illinois.edu; hanghang.tong@gmail.com; rmacieje@asu.edu
Systems & Rendering,1368,Edge-Path Bundling:  A Less Ambiguous Edge Bundling Approach,"Edge bundling techniques cluster edges with similar attributes (i.e. similarity in direction and proximity) together to reduce the visual clutter.  All edge bundling techniques to date implicitly or explicitly cluster groups of individual edges, or parts of them, together based on these attributes. These clusters can result in ambiguous connections that do not exist in the data. Confluent drawings of networks do not have these ambiguities, but require the layout to be computed as part of the bundling process.  We devise a new bundling method, edge-path bundling, to simplify edge clutter while greatly reducing ambiguities compared to previous bundling techniques. Edge-path bundling takes a layout as input and clusters each edge along a weighted, shortest path to limit its deviation from a straight line.  Edge-path bundling does not incur independent edge ambiguities typically seen in all edge bundling methods, and the level of bundling can be tuned through shortest path distances, Euclidean distances, and combinations of the two.  Also, directed edge bundling naturally emerges from the model. Through metric evaluations, we demonstrate the advantages of edge-path bundling over other techniques.",Graph/Network and Tree Data; Algorithms,Markus,Wallinger,Daniel,Archambault,David,Auber,Martin,Nöllenburg,Jaakko,Peltonen,,,,,,,,,,,,,,,,,Markus Wallinger: TU Wien; Daniel Archambault: Swansea University; David Auber: Univsity of Bordeaux; Martin Nöllenburg: TU Wien; Jaakko Peltonen: Tampere University,d.w.archambault@swansea.ac.uk; david.auber@u-bordeaux.fr; noellenburg@ac.tuwien.ac.at; jaakko.peltonen@tuni.fi
Theoretical & Empirical,1376,Visual Arrangements of Bar Charts Influence Comparisons in Viewer Takeaways,"Well-designed data visualizations can lead to more powerful and intuitive processing by a viewer. To help a viewer intuitively compare values to quickly generate key takeaways, visualization designers can manipulate how data values are arranged in a chart to afford particular comparisons. Using simple bar charts as a case study, we empirically tested the comparison affordances of four common arrangements: vertically juxtaposed, horizontally juxtaposed, overlaid, and stacked. We asked participants to type out what patterns they perceived in a chart and we coded their takeaways into types of comparisons. In a second study, we asked data visualization design experts to predict which arrangement they would use to afford each type of comparison and found both alignments and mismatches with our findings. These results provide concrete guidelines for how both human designers and automatic chart recommendation systems can make visualizations that help viewers extract the ``right'' takeaway.","Comparison, perception, visual grouping, bar charts, recommendation systems, computational linguistics",Cindy,Xiong,Vidya,Setlur,Benjamin,Bach,Kylie,Lin,Eunyee,Koh,Steven,Franconeri,,,,,,,,,,,,,,,Cindy Xiong: University of Massachusetts Amherst; Vidya Setlur: Tableau Research; Benjamin Bach: University of Edinburgh; Kylie R. Lin: Northwestern University; Eunyee Koh: Adobe Research; Steven Franconeri: Northwestern University,vsetlur@tableau.com; bbach@inf.ed.ac.uk; kylierlin@gmail.com; eunyee@adobe.com; franconeri@northwestern.edu
Theoretical & Empirical,1398,Rethinking the ranks of visual channels,"Data can be visually represented using visual channels like position, length or luminance.  An existing ranking of these visual channels is based on how accurately participants could report the ratio between two depicted values. There is an assumption that this ranking should hold for different tasks and for different numbers of marks. However, there is surprisingly little existing work that tests this assumption, especially given that visually computing ratios is relatively unimportant in real-world visualizations, compared to seeing, remembering, and comparing trends and motifs, across displays that almost universally depict more than two values.  To simulate the information extracted from a glance at a visualization, we instead asked participants to immediately reproduce a set of values from memory after they were shown the visualization. These values could be shown in a bar graph (position (bar)), line graph (position (line)), heat map (luminance), bubble chart (area), misaligned bar graph (length), or ‘wind map’ (angle).  
With a Bayesian multilevel modeling approach, we observed how the relevant rank positions of visual channels shift across different numbers of marks (2, 4 or 8) and for bias, precision, and error measures. The ranking did not hold, even for reproductions of only 2 marks, and the new ranking was highly inconsistent for reproductions of different numbers of marks. Other factors besides channel choice had an order of magnitude more influence on performance, such as the number of values in the series (e.g., more marks led to larger errors), or the value of each mark (e.g., small values were systematically overestimated). 
Every visual channel was worse for displays with 8 marks than 4, consistent with established limits on visual memory.
These results point to the need for a body of empirical studies that move beyond two-value ratio judgments as a baseline for ranking the quality of a visual channel, including testing new tasks (detection of trends or motifs), timescales (immediate computation, or later comparison), and the number of values (from a handful, to thousands).","DataType Agnostic; Human-Subjects Quantitative Studies; Perception & Cognition; Charts, Diagrams, and Plot",Caitlyn,McColeman,Fumeng,Yang,Timothy F.,Brady,Steven,Franconeri,,,,,,,,,,,,,,,,,,,Caitlyn M. McColeman: Northwestern University; Fumeng Yang: Brown University; Timothy F. Brady: University of California; Steven Franconeri: Northwestern University,fy@brown.edu; timbrady@ucsd.edu; franconeri@northwestern.edu
Theoretical & Empirical,1401,Accessible Visualization via Natural Language Descriptions: A Four-Level Model of Semantic Content,"Natural language descriptions (or captions) sometimes accompany visualizations to better communicate and contextualize their insights, and to improve their accessibility for readers with visual disabilities. However, it is difficult to evaluate the usefulness of these descriptions—and how effectively they improve access to meaningful information—because we have little understanding of the semantic content they convey, and how different readers receive this content. In response, we introduce a conceptual model for the semantic content conveyed via descriptions of visualizations. Developed through a grounded theory analysis of 2,147 natural language sentences, our model spans four levels of semantic content: enumerating visualization construction details (e.g., marks and encodings); identifying statistical concepts and relations (e.g., extrema and correlations); characterizing perceptual and cognitive phenomena (e.g., trends and patterns); and, communicating domain-specific insights or societal context. To demonstrate how our model can be applied to evaluate the effectiveness of visualization descriptions, we apply it in a mixed-methods evaluation with 30 blind and 90 sighted readers, and find that these readers differ significantly on which semantic content they rank as most useful. Together, our model and findings suggest that access to meaningful information is strongly reader-specific, and that automatic visualization captioning should orient toward descriptions more richly communicating a chart's overall trends and statistics, rather than detailing its visual construction alone. Our work further opens a space of research on natural language as a data interface coequal with visualization.","Visualization, natural language, description, caption, semantic, model, theory, alt-text, blind, disability, accessibility.",Alan,Lundgard,Arvind,Satyanarayan,,,,,,,,,,,,,,,,,,,,,,,Alan Lundgard: MIT; Arvind Satyanarayan: MIT,arvindsatya@mit.edu
Theoretical & Empirical,1417,Causal Support: Modeling Causal Inferences with Visualizations,"Analysts often make visual causal inferences about possible data-generating models. However, visual analytics (VA) software tends to leave these models implicit in the mind of the analyst, which casts doubt on the statistical validity of informal visual ""insights"". We formally evaluate the quality of causal inferences from visualizations by adopting causal support---a Bayesian cognition model that learns the probability of alternative causal explanations given some data---as a normative benchmark for causal inferences. We contribute two experiments assessing how well crowdworkers can detect (1) a treatment effect and (2) a confounding relationship. We find that chart users’ causal inferences tend to be insensitive to sample size such that they deviate from our normative benchmark. While interactively cross-filtering data in visualizations can improve sensitivity, on average users do not perform reliably better with common visualizations than they do with textual contingency tables. These experiments demonstrate the utility of causal support as an evaluation framework for inferences in VA and point to opportunities to make analysts' mental models more explicit in VA software.","Causal inference, visualization, contingency tables, data cognition",Alex,Kale,Yifan,Wu,Jessica,Hullman,,,,,,,,,,,,,,,,,,,,,Alex Kale: University of Washington; Yifan Wu: UC Berkeley; Jessica Hullman: Northwestern University,yifanwu@berkeley.edu; jhullman@northwestern.edu
Representations & Interaction,1419,Natural Language to Visualization by Neural Machine Translation,"Supporting the translation from natural language (NL) to visualization (NL2VIS) can simplify the creation of data visualizations, because if successful, anyone can generate visualizations by their natural language. The state-of-the-art NL2VIS approaches (e.g., NL4DV and FlowSense) are based on semantic parsers and heuristic algorithms, which are not end-to-end and are not designed for supporting (possibly) complex data transformations. Deep neural network powered neural machine translation models have made great strides in many machine translation tasks, which suggests that they might be viable for NL2VIS as well. In this paper, we present ncNet, a Transformer-based sequence-to-sequence model for supporting NL2VIS, with several novel visualization-aware optimizations, including using attention-forcing to optimize the learning process, and visualization-aware rendering to produce better visualization result. To enhance the capability of machine to comprehend natural language queries, ncNet is also designed to take an optional chart template (e.g., a pie chart or a scatter plot) as input, where the chart template will be served as a constraint to limit what could be visualized. We conducted both quantitative evaluation and user study, showing that neural machine translation techniques are easy-to-use and achieve good accuracy that is comparable with the state-of-the-art NL2SQL result.",Natural language interface; neural machine translation; chart template;,Yuyu,Luo,Nan,Tang,Guoliang,Li,Jiawei,Tang,Chengliang,Chai,Xuedi,Qin,,,,,,,,,,,,,,,Yuyu Luo: Tsinghua University; Nan Tang: QCRI; Guoliang Li: Tsinghua University; Jiawei Tang: American School of Doha; Chengliang Chai: Tsinghua University; Xuedi Qin: Tsinghua University,luoyy18@mails.tsinghua.edu.cn; liguoliang@tsinghua.edu.cn; joe.ntang@gmail.com; ccl@tsinghua.edu.cn; qxd17@mails.tsinghua.edu.cn
Data Transformations,1420,A Memory Efficient Encoding for Ray Tracing Large Unstructured Data,"In theory, efficient and high-quality rendering of unstructured data should greatly benefit from modern GPUs, but in practice, GPUs are often limited by the large amount of memory that large meshes require for element representation and for sample reconstruction acceleration structures. We describe a memory-optimized encoding for large unstructured meshes that efficiently encodes both the unstructured mesh and corresponding sample reconstruction acceleration structure, while still allowing for fast random-access sampling as required for rendering. We demonstrate that for large data our encoding is more efficient than OSPRay’s and allows for rendering even the 2.9 billion element Mars Lander on a single off-the-shelf GPU--and the largest 6.3 billion version on a pair of such GPUs.",Data Models ; Scalar Field Data ; Application Motivated Visualization ; Data Abstractions & Types ; Large-Scale Data Techniques ; Volume Rendering ; Computer Graphics Techniques ; Specific Computing and Rendering Hardware,Ingo,Wald,Nate,Morrical,Stefan,Zellmann,,,,,,,,,,,,,,,,,,,,,Ingo Wald: NVIDIA; Nate Morrical: University of Utah; Stefan Zellmann: University of Cologne,ingowald@gmail.com; zellmann@uni-koeln.de
Applications,1421,A Visualization Approach for Monitoring Order Processing in E-Commerce Warehouse,"The efficiency of warehouses is vital to e-commerce. Fast order processing at the warehouses ensures timely deliveries and improves customer satisfaction. However, monitoring, analyzing, and manipulating order processing in the warehouses in real time are challenging for traditional methods due to the sheer volume of incoming orders, the fuzzy definition of delayed order patterns, and the complex decision-making of order handling priorities. In this paper, we adopt a data-driven approach and propose OrderMonitor, a visual analytics system that assists warehouse managers in analyzing and improving order processing efficiency in real time based on streaming warehouse event data. Specifically, the order processing pipeline is visualized with a novel pipeline design based on the sedimentation metaphor to facilitate real-time order monitoring and suggest potentially abnormal orders. We also design a novel visualization that depicts order timelines based on the Gantt charts and Marey's graphs. Such a visualization helps the managers gain insights into the performance of order processing and find major blockers for delayed orders. Furthermore, an evaluating view is provided to assist users in inspecting order details and assigning priorities to improve the processing performance. The effectiveness of OrderMonitor is evaluated with two case studies on a real-world warehouse dataset.","Streaming data, time-series data, e-commerce warehouse, order processing",Junxiu,Tang,Yuhua,Zhou,Tan,Tang,Di,Weng,Boyang,Xie,Lingyun,Yu,Huaqiang,Zhang,Yingcai,Wu,,,,,,,,,,,Junxiu Tang: Zhejiang University; Yuhua Zhou: Zhejiang University; Tan Tang: Zhejiang University; Di Weng: Zhejiang University; Boyang Xie: Zhejiang University; Lingyun Yu: Xi'an Jiaotong-Liverpool University; Huaqiang Zhang: Alibaba Group; Yingcai Wu: Zhejiang University,zhouyuhua@zju.edu.cn; tangtan@zju.edu.cn; mystery.wd@gmail.com; xbyzju@gmail.com; lingyun.yu@xjtlu.edu.cn; huaqiang.zhq@cainiao.com; ycwu@zju.edu.cn
Data Transformations,1426,Feature Curves and Surfaces of 3D Asymmetric Tensor Fields,"3D asymmetric tensor fields have found many applications in science and engineering domains, such as fluid dynamics and solid mechanics. 3D asymmetric tensors can have complex eigenvalues, which makes their analysis and visualization more challenging than 3D symmetric tensors. Existing research in tensor field visualization focuses on 2D asymmetric tensor fields and 3D symmetric tensor fields. In this paper, we address the analysis and visualization of 3D asymmetric tensor fields. We introduce six topological surfaces and one topological curve, which lead to an eigenvalue space based on the tensor mode that we define. In addition, we identify several non-topological feature surfaces that are nonetheless physically important. Included in our analysis are the realizations that triple degenerate tensors are structurally stable and form curves, unlike the case for 3D symmetric tensors fields. Furthermore, there are two different ways of measuring the relative strengths of rotation and angular deformation in the tensor fields, unlike the case for 2D asymmetric tensor fields. We extract these feature surfaces using the A-patches algorithm. However, since three of our feature surfaces are quadratic, we develop a method to extract quadratic surfaces at any given accuracy. To facilitate the analysis of eigenvector fields, we visualize a hyperstreamline as a tree stem with the other two eigenvectors represented as thorns in the real domain or the dual-eigenvectors as leaves in the complex domain. To demonstrate the effectiveness of our analysis and visualization, we apply our approach to datasets from solid mechanics and fluid dynamics.","Tensor field visualization, 3D asymmetric tensor fields, tensor field topology, traceless tensors, feature surface extraction, degenerate surfaces, neutral surfaces, balanced surfaces, triple degenerate curves",Shih-Hsuan,Hung,Yue,Zhang,Harry,Yeh,Eugene,Zhang,,,,,,,,,,,,,,,,,,,Shih-Hsuan Hung: Oregon State University; Yue Zhang: Oregon State University; Harry Yeh: Oregon State University; Eugene Zhang: Oregon State University,hungsh@oregonstate.edu; zhangyue@oregonstate.edu; harry@oregonstate.edu
Systems & Rendering,1433,KD-Box: Line-segment-based KD-tree for Interactive Exploration of Large-scale Time-Series Data,"Time-series data—usually presented in the form of lines—plays an important role in many domains such as finance, meteorology, health, and urban informatics. Yet, little has been done to support interactive exploration of large-scale time-series data, which requires a clutter-free visual representation with low-latency interactions. In this paper, we contribute a novel line-segment-based KD-tree method to enable interactive analysis of many time series. Our method enables not only fast queries over time series in selected regions of interest but also a line splatting method for efficient computation of the density field and selection of representative lines. Further, we develop KD-Box, an interactive system that provides rich interactions, e.g., timebox, attribute filtering, and coordinated multiple views. We demonstrate the effectiveness of KD-Box in supporting efficient line query and density field computation through a quantitative comparison and show its usefulness for interactive visual analysis on several real-world datasets.","Many time series, density-based visualization, interactive visualization for large-scale data",Yue,Zhao,Jian,Zhang,Chi-Wing,Fu,Mingliang,Xu,Dominik,Moritz,Yunhai,Wang,,,,,,,,,,,,,,,Yue Zhao: School of Computer Science and Technology; Jian Zhang: CNIC; Chi-Wing Fu: The Chinese University of Hong Kong; Mingliang Xu: Zhengzhou University; Dominik Moritz: Carnegie Mellon University; Yunhai Wang: Shandong University,jack.zhao9802@gmail.com; zhangjian@sccas.cn; cwfu@cse.cuhk.edu.hk; iexumingliang@zzu.edu.cn; domoritz@cmu.edu
Representations & Interaction,1435,F2-Bubbles: Faithful Bubble Set Construction and Flexible Editing,"In this paper, we propose F2-Bubbles, a set overlay visualization technique that addresses overlapping artifacts and supports interactive editing with intelligent suggestions. The core of our method is a new, efﬁcient set overlay construction algorithm that approximates the optimal set overlay by considering set elements and their non-set neighbors. Thanks to the efﬁciency of the algorithm, interactive editing is achieved, and with intelligent suggestions, users can easily and ﬂexibly edit visualizations through direct manipulations with local adaptations. A quantitative comparison with state-of-the-art set visualization techniques and case studies demonstrate the effectiveness of our method and suggests that F2-Bubbles is a helpful technique for set visualization.","Set visualization, Edge Crossing, Minimal Spanning Tree",Yunhai,Wang,Da,Cheng,Zhirui,Wang,Jian,Zhang,Liang,Zhou,Gaoqi,He,Oliver,Deussen,,,,,,,,,,,,,Yunhai Wang: Shandong University; Da Cheng: Shandong University; Zhirui Wang: Shandong University; Jian Zhang: CNIC; Liang Zhou: Peking University; Gaoqi He: East China Normal University; Oliver Deussen: University of Konstanz,sduchd@gmail.com; russellwzrr@gmail.com; zhangjian@sccas.cn; zhoul@bjmu.edu.cn; gqhe@cs.ecnu.edu.cn; oliver.deussen@uni-konstanz.de
Data Transformations,1440,Attribute-based Explanations of Non-Linear Embeddings of High-Dimensional Data,"Embeddings of high-dimensional data are widely used to explore data, to verify analysis results, and to communicate information. Their explanation, in particular with respect to the input attributes, is often difficult. With linear projects like PCA the axes  can still be annotated meaningfully. With non-linear projections this is no longer possible and alternative strategies such as attribute-based color coding are required. In this paper, we review existing augmentation techniques and discuss their limitations. We present the Non-Linear Embeddings Surveyor (NoLiES) that combines a novel augmentation strategy for projected data (rangesets) with interactive analysis in a small multiples setting. Rangesets use a set-based visualization approach for binned attribute values that enable the user to quickly observe structure and detect outliers. We detail the link between algebraic topology and rangesets and demonstrate the utility of NoLiES in case studies with various challenges (complex attribute value distribution, many attributes, many data points) and a real-world application to understand latent features of matrix completion in thermodynamics.","Dimensionality reduction, embedding, augmented projections, point set contours, explainable artificial intelligence.",Jan-Tobias,Sohns,Michaela,Schmitt,Fabian,Jirasek,Hans,Hasse,Heike,Leitte,,,,,,,,,,,,,,,,,Jan-Tobias Sohns: TU Kaiserslautern; Michaela Schmitt: TU Kaiserslautern; Fabian Jirasek: TU Kaiserslautern; Hans Hasse: Unversity of Kaiserslautern; Heike Leitte: TU Kaiserslautern,j_sohns12@cs.uni-kl.de; m_schmitt13@cs.uni-kl.de; fabian.jirasek@mv.uni-kl.de; hans.hasse@mv.uni-kl.de
Applications,1452,Professional Differences: A Comparative Study of Visualization Task Performance and Spatial Ability Across Disciplines,"Problem-driven visualization work is rooted in deeply understanding the data, actors, processes, and workflows of a target domain. However, an individual's personality traits and cognitive abilities may also influence visualization use. Diverse user needs and abilities raise natural questions for specificity in visualization design: Could individuals from different domains exhibit performance differences when using visualizations? Are any systematic variations related to their cognitive abilities? This study bridges domain-specific perspectives on visualization design with those provided by cognition and perception. We measure variations in visualization task performance across chemistry, computer science, and education, and relate these differences to variations in spatial ability. We conducted an online study with over 60 domain experts consisting of tasks related to pie charts, isocontour plots, and 3D scatterplots, and grounded by a well-documented spatial ability test. Task performance (correctness) varied with profession across more complex visualizations (isocontour plots and scatterplots), but not pie charts, a comparatively common visualization. We found that correctness correlates with spatial ability, and the professions differ in terms of spatial ability. These results indicate that domains differ not only in the specifics of their data and tasks, but also in terms of how effectively their constituent members engage with visualizations and their cognitive traits. Analyzing participants' confidence and strategy comments suggests that focusing on performance neglects important nuances, such as differing approaches to engage with even common visualizations and potential skill transference. Our findings offer a fresh perspective on discipline-specific visualization with specific recommendations to help guide visualization design that celebrates the uniqueness of the disciplines and individuals we seek to serve.","discipline, domain-specific, task performance, spatial perception, perception study",Kyle,Hall,Anthony,Kouroupis,Anastasia,Bezerianos,Danielle,Szafir,Christopher,Collins,,,,,,,,,,,,,,,,,"Kyle Wm Hall: Temple University; Anthony Kouroupis: Ontario Tech University; Anastasia Bezerianos: Université Paris-Saclay, CNRS, INRIA; Danielle Albers Szafir: University of Colorado Boulder; Christopher Collins: Ontario Tech University",anthony.kouroupis@ontariotechu.net; anastasia.bezerianos@lri.fr; danielle.szafir@colorado.edu; christopher.collins@ontariotechu.ca
Applications,1462,matExplorer: Visual Exploration on Predicting of Ionic Conductivity for Solid-State Electrolytes ,"Lithium ion batteries (LIBs) are widely used as important energy sources for mobile phones, electric vehicles, and drones. Experts have attempted to replace liquid electrolytes with solid electrolytes that have wider electrochemical window and higher stability due to the potential safety risks, such as electrolyte leakage, flammable solvents, poor thermal stability, and many side reactions caused by liquid electrolytes. However, finding suitable alternative materials using traditional approaches is very difficult due to the incredibly high cost in searching. Machine learning (ML)-based methods are currently introduced and used for material prediction. However, learning tools designed for domain experts to conduct intuitive performance comparison and analysis of ML models are rare. In this case, we propose an interactive visualization system for experts to select suitable ML models and understand and explore the predication results comprehensively. Our system uses a multifaceted visualization scheme designed to support analysis from various perspectives, such as feature distribution, data similarity, model performance, and result presentation. Case studies with actual lab experiments have been conducted by the experts, and the final results confirmed the effectiveness and helpfulness of our system.","Interactive visualization, machine learning, materials discovery, ionic conductivity, high-dimensional data, solid-state electrolytes",Jiansu,Pu,Hui,Shao,Boyang,Gao,Zhengguo,Zhu,Yanlin,Zhu,Yunbo,Rao,Yong,Xiang,,,,,,,,,,,,,Jiansu Pu: University of Electronic Science and Technology of China; Hui Shao: University of Eletronic Science and Tech of China; Boyang Gao: University of Eletronic Science and Tech of China; Zhengguo Zhu: University of Eletronic Science and Tech of China; Yanlin Zhu: Shenzhen Clean Energy Research Institute; Yunbo Rao: University of Electronic Science and Technology of China(UESTC); Yong Xiang: University of Eletronic Science and Tech of China,sophyond@163.com; 202052080209@std.uestc.edu.cn; 202022080208@std.uestc.edu.cn; zhuyanlin@uceri.com; raoyb@uestc.edu.cn; 1370054330@qq.com
Data Transformations,1471,Joint t-SNE for Comparable Projections of Multiple High-Dimensional Datasets,"We present Joint t-Stochastic Neighbor Embedding (Joint t-SNE), a technique to generate comparable projections of multiple high-dimensional datasets. Although t-SNE has been widely employed to visualize high-dimensional datasets from various domains, it is limited to projecting a single dataset. When a series of high-dimensional datasets, such as datasets changing over time, is projected independently using t-SNE, misaligned layouts are obtained. Even items with identical features across datasets are projected to different locations, making the technique unsuitable for comparison tasks. To tackle this problem, we introduce edge similarity, which captures the similarities between two adjacent time frames based on the Graphlet Frequency Distribution (GFD). We then integrate a novel loss term into the t-SNE loss function, which we call vector constraints, to preserve the vectors between projected points across the projections, allowing these points to serve as visual landmarks for direct comparisons between projections. Using synthetic datasets whose ground-truth structures are known, we show that Joint t-SNE outperforms existing techniques, including Dynamic t-SNE, in terms of local coherence error, Kullback-Leibler divergence, and neighborhood preservation. We also showcase a real-world use case to visualize and compare the activation of different layers of a neural network.","High-dimensional data, projection, embedding, t-stochastic neighbor embedding",Yinqiao,Wang,Lu,Chen,Jaemin,Jo,Yunhai,Wang,,,,,,,,,,,,,,,,,,,Yinqiao Wang: Shandong University; Lu Chen: Shandong University; Jaemin Jo: Sungkyunkwan University; Yunhai Wang: Shandong University,infamywong@gmail.com; chenlu.scien@gmail.com; jmjo@skku.edu
Representations & Interaction,1477,spEuler: Semantics-preserving Euler Diagrams,"Creating comprehensible visualizations of highly overlapping set-typed data is a challenging task due to its complexity. 
To facilitate insights into set connectivity and to leverage semantic relations between intersections, we propose a fast two-step layout technique for Euler diagrams that are both well-matched and well-formed. 
Our method conforms to established form guidelines for Euler diagrams regarding semantics, aesthetics, and readability. 
First, we establish an initial ordering of the data, which we then use to incrementally create a planar, connected, and monotone dual graph representation. 
In the next step, the graph is transformed into a circular layout that maintains the semantics and yields simple Euler diagrams with smooth curves. 
When the data cannot be represented by simple diagrams, our algorithm always falls back to a solution that is not well-formed but still well-matched, whereas previous methods often fail to produce expected results. 
We show the usefulness of our method for visualizing set-typed data using examples from text analysis and infographics. 
Furthermore, we discuss the characteristics of our approach and evaluate our method against state-of-the-art methods.","Euler diagrams, Venn diagrams, set visualization, layout algorithm",Rebecca,Kehlbeck,Jochen,Görtler,Yunhai,Wang,Oliver,Deussen,,,,,,,,,,,,,,,,,,,Rebecca Kehlbeck: University of Konstanz; Jochen Görtler: University of Konstanz; Yunhai Wang: Shandong University; Oliver Deussen: University of Konstanz,jochen.goertler@uni-konstanz.de; cloudseawang@gmail.com; oliver.deussen@uni-konstanz.de
Applications,1480,Visual Evaluation for Autonomous Driving,"Autonomous driving technologies often use state-of-the-art artificial intelligence algorithms to understand the relationship between the vehicle and the external environment, to predict the changes of the environment, and then to plan and control the behaviors of the vehicle accordingly. The complexity of such technologies makes it challenging to evaluate the performance of autonomous driving systems and to find ways to improve them. The current approaches to evaluating such autonomous driving systems largely use a single score to indicate the overall performance of a system, but domain experts have difficulties in understanding how individual components or algorithms in an autonomous driving system may contribute to the score. To address this problem, we collaborate with domain experts on autonomous driving algorithms, and propose a visual evaluation method for autonomous driving. Our method considers the data generated in all components during the whole process of autonomous driving, including perception results, planning routes, prediction of obstacles, various controlling parameters, and evaluation of comfort. We develop a visual analytics workflow to integrate an evaluation mathematical model with adjustable parameters, support the evaluation of the system from the level of the overall performance to the level of detailed measures of individual components, and to show both evaluation scores and their contributing factors. Our implemented visual analytics system provides an overview evaluation score at the beginning and shows the animation of the dynamic change of the scores at each period. Experts can interactively explore the specific component at different time periods and identify related factors. With our method, domain experts not only learn about the performance of an autonomous driving system, but also identify and access the problematic parts of each component. Our visual evaluation system can be applied to the autonomous driving simulation system and used for various evaluation cases. The results of using our system in some simulation cases and the feedback from involved domain experts confirm the usefulness and efficiency of our method in helping people gain in-depth insight into autonomous driving systems.","Geospatial Data ; Application Motivated Visualization ; Machine Learning, Statistics, Modelling, and Simulation Applications ; Data Analysis, Reasoning, Problem Solving, and Decision Making",Yijie,Hou,Chengshun,Wang,Junhong,Wang,Xiangyang,Xue,Xiaolong,Zhang,Jun,Zhu,Dongliang,Wang,Siming,Chen,,,,,,,,,,,"Yijie Hou: Fudan University; Chengshun Wang: Fudan University; Junhong Wang: Fudan University; Xiangyang Xue: Fudan University; Xiaolong (Luke) Zhang: Penn State; Jun Zhu: China FAW (Nanjing) Technology Development Co., Ltd; Dongliang Wang: China FAW (Nanjing) Technology Development Co., Ltd; Siming Chen: Fudan University",20210980031@fudan.edu.cn; 20210980030@fudan.edu.cn; xyxue@fudan.edu.cn; lzhang@ist.psu.edu; zhujun18@faw.com.cn; wangdongliang@faw.com.cn; simingchen3@gmail.com
Applications,1486,AffectiveTDA: Using Topological Data Analysis for Improved Explainability in Affective Computing,"We present an approach utilizing Topological Data Analysis to study the structure of face poses used in affective computing, i.e., the process of recognizing human emotion. The approach uses a conditional comparison of different emotions, both respective and irrespective of time, with multiple topological distance metrics, dimension reduction techniques, and face subsections (e.g., eyes, nose, mouth, etc.). The results confirm that our topology-based approach captures known patterns, distinctions between emotions, and distinctions between individuals, which is an important step towards more robust and explainable emotion recognition by machines.","Affective computing, topological data analysis, explainability, visualization",Hamza,Elhamdadi,Shaun,Canavan,Paul,Rosen,,,,,,,,,,,,,,,,,,,,,Hamza Elhamdadi: University of South Florida; Shaun Canavan: University of South Florida; Paul Rosen: University of South Florida,hme1@usf.edu; scanavan@usf.edu
Analytics & Decisions,1490,GenNI: Human-AI Collaboration for Data-Backed Text Generation  ,"Table2Text systems generate textual output based on structured data utilizing machine learning. These systems are essential for fluent natural language interfaces in tools such as virtual assistants; however, left to generate freely these ML systems often produce misleading or unexpected outputs. GenNI (Generation Negotiation Interface) is an interactive visual system for high-level human-AI collaboration in producing descriptive text. The tool utilizes a deep learning model designed with explicit control states. These controls allow users to globally constrain model generations, without sacrificing the representation power of the deep learning models. The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable. We report multiple use cases on two experiments that improve over uncontrolled generation approaches, while at the same time providing fine-grained control.","Explainable AI, Machine Learning, Visualization",Hendrik,Strobelt,Jambay,Kinley,Robert,Krüger,Johanna,Beyer,Hanspeter,Pfister,Alexander,Rush,,,,,,,,,,,,,,,Hendrik Strobelt: IBM Research AI; Jambay Kinley: Cornell University; Robert Krüger: John A. Paulson School of Engineering and Applied Sciences at Harvard University; Johanna Beyer: Harvard University; Hanspeter Pfister: Harvard University; Alexander Rush: Cornell University,j_kinley@college.harvard.edu; krueger@g.harvard.edu; johanna.m.beyer@gmail.com; pfister@seas.harvard.edu; arush@cornell.edu
Applications,1492,Sibyl: Understanding and Addressing the Usability Challenges of Machine Learning In High-Stakes Decision Making,"Machine learning (ML) is being applied to a diverse and ever-growing set of domains. In many cases, domain experts --- who often have no expertise in ML or data science --- are asked to use ML predictions to make high-stakes decisions. Multiple ML usability challenges can appear as result, such as lack of user trust in the model, inability to reconcile human-ML disagreement, and ethical concerns about oversimplification of complex problems to a single algorithm output. In this paper, we investigate the ML usability challenges that present in the domain of child welfare screening through a series of collaborations with child welfare screeners. Following the iterative design process between the ML scientists, visualization researchers, and domain experts (child screeners), we first identified four key ML challenges and honed in on one promising explainable ML technique to address them (local factor contributions). Then we designed, implemented, and evaluated our visual analytics tool, Sibyl, to increase the interpretability and interactivity of local factor contributions. The effectiveness of our tool is demonstrated by two formal user studies with 12 non-expert participants and 13 expert participants respectively. Valuable feedback is collected, from which we also composed a list of design implications as a useful guideline for researchers that aim to develop an interpretable and interactive visualization tool for ML prediction models deployed for child welfare screeners and other similar domain experts.","Machine learning, XAI, usability, child welfare, visualization",Alexandra,Zytek,Dongyu,Liu,Rhema,Vaithianathan,Kalyan,Veeramachaneni,,,,,,,,,,,,,,,,,,,Alexandra Zytek: MIT; Dongyu Liu: MIT; Rhema Vaithianathan: Auckland University of Technology; Kalyan Veeramachaneni: MIT,ustdongyu@gmail.com; rhema.vaithianathan@aut.ac.nz; kalyanv@mit.edu
Analytics & Decisions,1494,Interactive Visual Pattern Search on Graph Data via Graph Representation Learning,"Graphs are a ubiquitous data structure to model processes and relations in a wide range of domains. Examples include social networks, knowledge graphs, control-flow graphs in programs, and semantic scene graphs in images. Identifying subgraph patterns (or motifs) in graphs is one important approach to understand their structural properties. We propose a visual analytics system, GraphQ to support human-in-the-loop, example-based, subgraph pattern search in a database containing many individual graphs. Our approach goes beyond a predefined set of motifs and allows users to interactively specify the patterns of interest. To support fast, interactive queries, we use graph neural networks (GNNs) to encode the topological and node attributes in a graph as fixed-length
latent vector representations, and perform subgraph matching in the latent space. However, due to the complexity of the problem, it is still difficult to obtain accurate one-to-one node correspondence in the matching results, which is crucial for visualization and
interpretation. We, therefore, propose a novel GNN for node-alignment called NeuroAlign, to facilitate easy validation and interpretation of the query results. GraphQ provides a visual query interface with a query editor and a multi-scale visualization of the results, as well as a user feedback mechanism for refining the results with additional constraints. We demonstrate GraphQ through two example usage scenarios in different application domains: analyzing reusable subroutines in program workflows and semantic scene graph search in images. Quantitative experiments show that NeuroAlign achieves 19%–29% improvement in node-alignment accuracy compared to baseline GNN and provides up to 100x speedup compared to combinatorial algorithms. Our qualitative study with domain experts confirms the effectiveness of GraphQ for both usage scenarios.","Graph, Graph Neural Network, Representation Learning, Visual Query Interface",Huan,Song,Zeng,Dai,Panpan,Xu,Liu,Ren,,,,,,,,,,,,,,,,,,,Huan Song: Bosch Research; Zeng Dai: Bosch Research; Panpan Xu: Bosch Research; Liu Ren: Robert Bosch Research,huan.song@us.bosch.com; zeng.dai@us.bosch.com; liu.ren@us.bosch.com
Theoretical & Empirical,1500,Communicating Visualizations without Visuals: Investigation of Visualization Alternative Text for People with Visual Impairments,"Alternative text is critical in communicating graphics to people who are blind or have low vision. Especially for graphics that contain rich information, such as visualizations, poorly written or an absence of alternative texts can worsen the information access inequality for people with visual impairments. In this work, we consolidate existing guidelines and survey current practices to inspect to what extent current practices and recommendations are aligned. Then, to gain more insight into what people want in visualization alternative texts, we interviewed 22 people with visual impairments regarding their experience with visualizations and their information needs in alternative texts. The study findings suggest that participants actively try to construct an image of visualizations in their head while listening to alternative texts and wish to carry out visualization tasks (e.g., retrieve specific values) as sighted viewers would. The study also provides ample support for the need to reference the underlying data instead of visual elements to reduce users’ cognitive burden. Informed by the study, we provide a set of recommendations to compose an informative alternative text.","accessible visualization, assistive technologies, alternative text for graphics",Crescentia,Jung,Shubham,Mehta,Atharva,Kulkarni,Yuhang,Zhao,Yea-Seul,Kim,,,,,,,,,,,,,,,,,Crescentia Jung: University of Wisconsin-Madison; Shubham R Mehta: University of Wisconsin-Madison ; Atharva Kulkarni: University of Wisconsin Madison; Yuhang Zhao: University of Wisconsin-Madison; Yea-Seul Kim: University of Wisconsin-Madison,shubhammehta5588@gmail.com; akulkarni23@wisc.edu; yuhang.zhao@cs.wisc.edu; yeaseul.kim@cs.wisc.edu
Representations & Interaction,1502,Scope2Screen: Focus+Context Techniques for Pathology Tumor Assessment in Multivariate Image Data,"Inspection of tissues using a light microscope is the primary method of diagnosing many diseases, notably cancer.  Highly multiplexed tissue imaging builds on this foundation, enabling collection of up to 60 channels of molecular information plus cell and tissue morphology using antibody staining. This provides unique insight into disease biology and promises to help with design of patient-specific therapies.  However, a substantial gap remains with respect to visualizing the resulting multivariate image data and effectively supporting pathology workflows in digital environments on screen. We, therefore, developed Scope2Screen, a scalable software system for focus+context exploration and annotation of whole-slide, high-plex, tissue images. Our approach scales to analyzing 100GB images of 10^9 or more pixels per channel, containing millions of individual cells.  A multidisciplinary team of visualization experts, microscopists, and pathologists identified key image exploration and annotation tasks involving finding, magnifying, quantifying, and organizing regions of interest (ROIs) in an intuitive and cohesive manner. Building on a scope-to-screen metaphor, we present interactive lensing techniques that operate at single-cell and tissue levels. Lenses are equipped with task-specific functionality and descriptive statistics, making it possible to analyze image features, cell types, and spatial arrangements (neighborhoods) across image channels and scales. A fast sliding-window search guides users to regions similar to those under the lens; these regions can be analyzed and considered either separately or as part of a larger image collection.  A novel snapshot method enables linked lens configurations and image statistics to be saved, restored, and shared with these regions. We validate our designs with domain experts and apply Scope2Screen in two case studies involving lung and colorectal cancers to discover cancer-relevant image features.","Histopathology, Focus+Context, Image Analysis",Jared,Jessup,Robert,Krüger,Simon,Warchol,John,Hoffer,Jeremy,Muhlich,Cecily C.,Ritch,Giorgio,Gaglia,Shannon,Coy,Yu-An,Chen,Jia-Ren,Lin,Sandro,Santagata,Peter,Sorger,Hanspeter,Pfister,Jared Jessup: Harvard University; Robert Krüger: Harvard University; Simon Alexander Warchol: Harvard University; John Hoffer: Harvard Medical School; Jeremy Muhlich: Harvard Medical School; Cecily C. Ritch: Harvard Medical School; Giorgio Gaglia: Harvard Medical School; Shannon Coy: Harvard Medical School; Yu-An Chen: Harvard Medical School; Jia-Ren Lin: Harvard Medical School; Sandro Santagata Santagata: Harvard Medical School; Peter Sorger: Harvard Medical School; Hanspeter Pfister: Harvard University,jessupjs@gmail.com; simonwarchol@g.harvard.edu; john_hoffer@hms.harvard.edu; jeremy_muhlich@hms.harvard.edu; critch@bwh.harvard.edu; ggaglia@bwh.harvard.edu; scoy@partners.org; yu-an_chen@hms.harvard.edu; jia-ren_lin@hms.harvard.edu; ssantagata@bics.bwh.harvard.edu; peter_sorger@hms.harvard.edu; pfister@seas.harvard.edu
Applications,1504,THALIS: Human-Machine Analysis of Longitudinal Symptoms in Cancer Therapy,"Although cancer patients survive years after oncologic therapy, they are plagued with long-lasting or permanent residual symptoms, whose severity, rate of development, and resolution after treatment vary largely between survivors. The analysis and interpretation of symptoms is complicated by their partial co-occurrence, variability across populations and across time, and, in the case of cancers that use radiation, by further symptom dependency on the prescribed therapy. We describe an integrated environment for visual analysis and knowledge discovery from cancer therapy symptom data, developed in close collaboration with oncology experts. Our visual environment leverages unsupervised machine learning methodology over cohorts of patients, and, in conjunction with custom visual encodings and interactions, provides context for new patients based on patients with similar diagnostic features and symptom evolution. We evaluate this environment on data collected from a cohort of head and neck cancer patients. Feedback from our clinician collaborators indicates that this environment supports knowledge discovery beyond the limits of machines or humans alone, and that it serves as a valuable tool in both the clinic and symptom research.",Temporal Data; Application Motivated Visualization; Life Sciences; Mixed Initiative Human-Machine Analysis,Carla,Floricel,Md Nafiul,Nipu,Mikayla,Biggs,Andrew,Wentzel,Guadalupe,Canahuate,Lisanne,van Dijk,Abdallah,Mohamed,Clifton David,Fuller,G. Elisabeta,Marai,,,,,,,,,Carla Gabriela Floricel: University of Illinois at Chicago; Md Nafiul Alam Nipu: University of Illinois at Chicago ; Mikayla Biggs: University of Iowa; Andrew Wentzel: University of Illinois at Chicago; Guadalupe Canahuate: University of Iowa; Lisanne van Dijk: University of Texas; Abdallah Mohamed: University of Texas; Clifton David Fuller: University of Texas; G. Elisabeta Marai: University of Illinois at Chicago,mnipu2@uic.edu; mikayla-biggs@uiowa.edu; awentze2@uic.edu; guadalupe-canahuate@uiowa.edu; lvvan@mdanderson.org; asmohamed@mdanderson.org; cdfuller@mdanderson.org; g.elisabeta.marai@gmail.com
Analytics & Decisions,1517,Where Can We Help? A Visual Analytics Approach to Diagnosing and Improving Semantic Segmentation of Movable Objects,"Semantic segmentation is a critical component in autonomous driving and has to be thoroughly evaluated due to safety concerns. Deep neural network (DNN) based semantic segmentation models are widely used in autonomous driving. However, it is challenging to evaluate DNN-based models due to their black-box-like nature, and it is even more difficult to assess model performance for crucial objects, such as lost cargos and pedestrians, in autonomous driving applications. In this work, we propose VASS, a Visual Analytics approach to diagnosing and improving the accuracy and robustness of Semantic Segmentation models, especially for critical objects moving in various driving scenes. The key component of our approach is a context-aware spatial representation learning that extracts important spatial information of objects, such as position, size, and aspect ratio, with respect to given scene contexts. Based on this spatial representation, we first use it to create visual summarization to analyze models’ performance. We then use it to guide the generation of adversarial examples to evaluate models’ spatial robustness and obtain actionable insights. We demonstrate the effectiveness of VASS via two case studies of lost cargo detection and pedestrian detection in autonomous driving. For both cases, we show quantitative evaluation on the improvement of models’ performance with actionable insights obtained from VASS.","Model diagnosis, semantic segmentation, spatial representation learning, adversarial learning, autonomous driving",Wenbin,He,Lincan,Zou,Shekar Arvind,Kumar,Liang,Gou,Liu,Ren,,,,,,,,,,,,,,,,,Wenbin He: Bosch Research North America; Lincan Zou: Bosch Research and Technology Center North America; Shekar Arvind Kumar: Robert Bosch GmbH; Liang Gou: Bosch Research; Liu Ren: Robert Bosch Research,lczou20@gmail.com; arvindkumar.shekar@de.bosch.com; lgou.psu@gmail.com; liu.ren@us.bosch.com
Analytics & Decisions,1524,Geo-Context Aware Study of Vision-Based Autonomous Driving Models and Spatial Video Data,"Vision-based deep learning (DL) methods have achieved success in learning autonomous driving models from large scale crowd-sourced video datasets. They are trained to predict instantaneous driving behaviors from video data captured by on-vehicle cameras. In this paper, we develop a geo-context aware visualization system for the study of Autonomous Driving Model (ADM) predictions together with large scale ADM video data. The visual study is seamlessly integrated with the geographical environment by combining DL model performance with geospatial visualization techniques. Model performance measures can be studied together with a set of geo-spatial attributes over map views. Users can also discover and compare prediction behaviors of multiple DL models in both city-wide and street-level analysis, together with road images and video contents. Therefore, the system provides a new visual exploration platform for DL model designers in autonomous driving. Use cases and domain expert evaluation show the utility and effectiveness of the visualization system.","Visualization System, Spatial Video, Autonomous Driving, Vision-based Deep Learning Models",Suphanut,Jamonnak,Ye,Zhao,Xinyi,Huang,Md,Amiruzzaman,,,,,,,,,,,,,,,,,,,Suphanut Jamonnak: Kent State University; Ye Zhao: Kent State University; Xinyi Huang: Kent State University; Md Amiruzzaman: Kent State University,zhao@cs.kent.edu; xhuang5@kent.edu; m.amiruzzaman@gmail.com
Theoretical & Empirical,1532,Revisiting Dimensionality Reduction Approaches for Visual Cluster Analysis: An Empirical Study,"Dimensionality Reduction (DR) techniques can generate 2D projections and enable visual exploration of cluster structures of high-dimensional datasets. However, different DR techniques would yield various patterns, which significantly affect the performance of visual cluster analysis tasks. We present the results of a user study that investigates the influence of different DR techniques on visual cluster analysis. Our study focuses on the most concerned property types, namely the linearity and locality, and evaluates twelve representative DR techniques that cover the concerned properties. Four controlled experiments were conducted to evaluate how the DR techniques facilitate the tasks of 1) identifying clusters, 2) associating cluster members, 3) comparing distances among clusters, and 4) comparing cluster densities, respectively. We also evaluated users’ subjective preference of the DR techniques regarding the quality of projected clusters. The results show that: 1) Non-linear and Local techniques are preferred in identifying clusters and associating cluster members; 2) Linear techniques perform better than non-linear techniques in comparing cluster densities; 3) UMAP (Uniform Manifold Approximation and Projection) and t-SNE (t-Distributed Stochastic Neighbor Embedding) perform the best in identifying clusters and associating cluster members; 4) NMF(Nonnegative Matrix Factorization) has competitive performance in comparing distances among clusters; 5) t-SNLE(t-Distributed Stochastic Neighbor Linear Embedding) has competitive performance in comparing cluster densities.","Dimensionality reduction, visual cluster analysis, perception-based evaluation",Jiazhi,Xia,Yuchen,Zhang,Jie,Song,Yang,Chen,Yunhai,Wang,Shixia,Liu,,,,,,,,,,,,,,,Jiazhi Xia: Central South University; Yuchen Zhang: Central South University; Jie Song: Central South University; Yang Chen: I4 data; Yunhai Wang: Shandong University; Shixia Liu: Tsinghua University,184612320@csu.edu.cn; jiesong@csu.edu.cn; chen1984yang@gmail.com; cloudseawang@gmail.com; shixia@tsinghua.edu.cn
Applications,1558,ThreadStates: State-based Visual Analysis of Disease Progression,"A growing number of longitudinal cohort studies are generating data with extensive patient observations across multiple timepoints. Such data offers promising opportunities to better understand the progression of diseases. However, these observations are usually treated as general events in existing visual analysis tools. As a result, their capabilities in modeling disease progression are not fully utilized. To fill this gap, we designed and implemented ThreadStates, an interactive visual analytics tool for the exploration of longitudinal patient cohort data. The focus of ThreadStatesis to identify the states of disease progression by learning from observation data in a human-in-the-loop manner. We propose a novel Glyph Matrix design and combine it with a scatter plot to enable seamless identification, observation, and refinement of states. The disease progression patterns are then revealed in terms of state transitions using Sankey-based visualizations.  We employ sequence clustering techniques to find patient groups with distinctive progression patterns, and to reveal the association between disease progression and patient-level features. The design and development were driven by a requirement analysis and iteratively refined based on feedback from domain experts over the course of a 10-month design study. Case studies and expert interviews demonstrate that ThreadStates can successively summarize disease states, reveal disease progression, and compare patient groups.","Disease Progression, State Identification, Sequence Visualization",Qianwen,Wang,Tali,Mazor,Theresa,Harbig,Ethan,Cerami,Nils,Gehlenborg,,,,,,,,,,,,,,,,,Qianwen Wang: Harvard Medical School; Tali Mazor: Dana-Farber Cancer Institute; Theresa Harbig: University of Tubingen; Ethan Cerami: Dana-Farber Cancer Institute; Nils Gehlenborg: Harvard Medical School,tmazor@ds.dfci.harvard.edu; theresa_harbig@hms.harvard.edu; cerami@jimmy.harvard.edu; nils@hms.harvard.edu
Analytics & Decisions,1570,Interactive Dimensionality Reduction for Comparative Analysis,"Finding the similarities and differences between two or more groups of datasets is a fundamental analysis task. For high-dimensional data, dimensionality reduction (DR) methods are often used to find the characteristics of each group. However, existing DR methods provide limited capability and flexibility for such comparative analysis as each method is designed only for a narrow analysis target, such as identifying factors that most differentiate groups. In this work, we introduce an interactive DR framework where we integrate our new DR method, called ULCA (unified linear comparative analysis), with an interactive visual interface. ULCA unifies two DR schemes, discriminant analysis and contrastive learning, to support various comparative analysis tasks. To provide flexibility for comparative analysis, we develop an optimization algorithm that enables analysts to interactively refine ULCA results. Additionally, we provide an interactive visualization interface to examine ULCA results with a rich set of analysis libraries. We evaluate ULCA and the optimization algorithm to show their efficiency as well as present multiple case studies using real-world datasets to demonstrate the usefulness of our framework.","Dimensionality reduction, discriminant analysis, contrastive learning, comparative analysis, interpretability, visual analytics.",Takanori,Fujiwara,Xinhai,Wei,Jian,Zhao,Kwan-Liu,Ma,,,,,,,,,,,,,,,,,,,"Takanori Fujiwara: University of California, Davis; Xinhai Wei: University of Waterloo; Jian Zhao: University of Waterloo; Kwan-Liu Ma: University of California at Davis",x67wei@uwaterloo.ca; jianzhao@uwaterloo.ca; ma@cs.ucdavis.edu
Applications,1578,Augmenting Sports Videos with VisCommentator,"Visualizing data in sports videos is gaining traction in sports analytics, given its ability to communicate insights and explicate player strategies engagingly. However, augmenting sports videos with such data visualizations is challenging, especially for sports analysts, as it requires considerable expertise in video editing. To ease the creation process, we present a design space that characterizes augmented sports videos at an element-level (what the constituents are) and clip-level (how those constituents are organized). We do so by systematically reviewing 233 examples of augmented sports videos collected from TV channels, teams, and leagues. The design space guides selection of data insights and visualizations for various purposes. Informed by the design space and close collaboration with domain experts, we design VisCommentator, a fast prototyping tool, to eases the creation of augmented table tennis videos by leveraging machine learning-based data extractors and design space-based visualization recommendations. With VisCommentator, sports analysts can create an augmented video by selecting the data to visualize instead of manually drawing the graphical marks. Our system can be generalized to other racket sports (e.g., tennis, badminton) once the underlying datasets and models are available. A user study with seven domain experts shows high satisfaction with our system, confirms that the participants can reproduce augmented sports videos in a short period, and provides insightful implications into future improvements and opportunities.","Augmented Sports Videos, Video-based Visualization, Sports visualization, Intelligent Design Tool, Storytelling",Zhutian,Chen,Shuainan,Ye,Xiangtong,Chu,Haijun,Xia,Hui,Zhang,Huamin,Qu,Yingcai,Wu,,,,,,,,,,,,,"Zhutian Chen: University of California San Diego; Shuainan Ye: Zhejiang University; Xiangtong Chu: Zhejiang University; Haijun Xia: University of California, San Diego; Hui Zhang: Zhejiang University; Huamin Qu: The Hong Kong University of Science and Technology; Yingcai Wu: Zhejiang University",sn_ye@outlook.com; chuxiangtong@zju.edu.cn; haijunxia@ucsd.edu; zhang_hui@zju.edu.cn; huamin@cse.ust.hk; ycwu@zju.edu.cn
Systems & Rendering,1582,Interactive Exploration of Physically-Observable Objective Vortices in Unsteady 2D Flow,"State-of-the-art computation and visualization of vortices in unsteady fluid flow employ objective vortex criteria, which makes them independent of reference frames or observers. However, objectivity by itself, although crucial, is not sufficient to guarantee that one can identify physically-realizable observers that would perceive or detect the same vortices. Moreover, a significant challenge is that a single reference frame is often not sufficient to accurately observe multiple vortices that follow different motions. This paper presents a novel framework for the exploration and use of an interactively-chosen set of observers, of the resulting relative velocity fields, and of objective vortex structures. We show that our approach facilitates the objective detection and visualization of vortices relative to well-adapted reference frame motions, while at the same time guaranteeing that these observers are in fact physically realizable. In order to represent and manipulate observers efficiently, we make use of the low-dimensional vector space structure of the Lie algebra of physically-realizable observer motions. We illustrate that our framework facilitates the efficient choice and guided exploration of objective vortices in unsteady 2D flow, on planar as well as on spherical domains, using well-adapted reference frames.","Flow visualization, vortex detection, objectivity, observers, reference frames, Lie algebras",Xingdi,Zhang,Markus,Hadwiger,Thomas,Theussl,Peter,Rautek,,,,,,,,,,,,,,,,,,,Xingdi Zhang: King Abdullah University of Science and Technology (KAUST); Markus Hadwiger: King Abdullah University of Science and Technology (KAUST); Thomas Theussl: King Abdullah University of Science and Technology (KAUST); Peter Rautek: King Abdullah University of Science and Technology (KAUST),xingdi.zhang@kaust.edu.sa; thomas.theussl@kaust.edu.sa; peter.rautek@kaust.edu.sa
Applications,1583,VisQA: X-raying Vision and Language Reasoning in Transformers,"Visual Question Answering systems target answering open-ended textual questions given input images. They are a testbed for learning high-level reasoning with a primary use in HCI, for instance assistance for the visually impaired. Recent research has shown that state-of-the-art models tend to produce answers exploiting biases and shortcuts in the training data, and sometimes do not even look at the input image, instead of performing the required reasoning steps. We present VisQA, a visual analytics tool that explores this question of reasoning vs. bias exploitation. It exposes the key element of state-of-the-art neural models --- attention maps in transformers. Our working hypothesis is that reasoning steps leading to model predictions are observable from attention distributions, which are particularly useful for visualization. The design process of VisQA was motivated by well-known bias examples from the fields of deep learning and vision-language reasoning and evaluated in two ways. First, as a result of a collaboration of three fields, machine learning, vision and language reasoning, and data analytics, the work lead to a better understanding of bias exploitation of neural models for VQA, which eventually resulted in an impact on its design and training through the proposition of a method for the transfer of reasoning patterns from an oracle model. Second, we also report on the design of VisQA, and a goal-oriented evaluation of VisQA targeting the analysis of a model decision process from multiple experts, providing evidence that it makes the inner workings of models accessible to users.","Transformers, Visual Question Answering, Visual analytics",Theo,Jaunet,Corentin,Kervadec,Romain,Vuillemot,Grigory,Antipov,Moez,Baccouche,Christian,Wolf,,,,,,,,,,,,,,,"Theo Jaunet: INSA-Lyon; Corentin Kervadec: LIRIS, INSA Lyon; Romain Vuillemot: Ecole Centrale de Lyon; Grigory Antipov: Orange; Moez Baccouche: Orange; Christian Wolf: INSA-Lyon, Inria",corentin.kervadec@orange.com; romain.vuillemot@gmail.com; grigory.antipov@orange.com; moez.baccouche@orange.com; christian.wolf@insa-lyon.fr
Systems & Rendering,1586,Probabilistic Occlusion Culling using Confidence Maps for High-Quality Rendering of Large Particle Data,"Achieving high rendering quality in the visualization of large particle data, for example from large-scale molecular dynamics simulations, requires a significant amount of sub-pixel super-sampling, due to very high numbers of particles per pixel. Although it is impossible to super-sample all particles of large-scale data at interactive rates, efficient occlusion culling can decouple the overall data size from a high effective sampling rate of visible particles. However, while the latter is essential for domain scientists to be able to see important data features, performing occlusion culling by sampling or sorting the data is usually slow or error-prone due to visibility estimates of insufficient quality. We present a novel probabilistic culling architecture for super-sampled high-quality rendering of large particle data. Occlusion is dynamically determined at the sub-pixel level, without explicit visibility sorting or data simplification. We introduce confidence maps to probabilistically estimate confidence in the visibility data gathered so far. This enables progressive, confidence-based culling, helping to avoid wrong visibility decisions. In this way, we determine particle visibility with high accuracy, although only a small part of the data set is sampled. This enables extensive super-sampling of (partially) visible particles for high rendering quality, at a fraction of the cost of sampling all particles. For real-time performance with millions of particles, we exploit novel features of recent GPU architectures to group particles into two hierarchy levels, combining fine-grained culling with high frame rates.","Large-scale particle data, sub-pixel occlusion culling, super-sampling, anti-aliasing, coverage, probabilistic methods",Mohamed,Ibrahim,Peter,Rautek,Guido,Reina,Marco,Agus,Markus,Hadwiger,,,,,,,,,,,,,,,,,Mohamed Ibrahim: King Abdullah University of Science and Technology (KAUST); Peter Rautek: King Abdullah University of Science and Technology (KAUST); Guido Reina: University of Stuttgart; Marco Agus: Hamad Bin Khalifa University; Markus Hadwiger: King Abdullah University of Science and Technology (KAUST),moeizle@gmail.com; peter.rautek@kaust.edu.sa; guido.reina@visus.uni-stuttgart.de; magus@hbku.edu.qa
Representations & Interaction,1590,GlyphCreator: Towards Automatic Generation of Example-based Circular Glyphs,"Circular glyphs are widely used in different fields because of their effectiveness in representing multidimensional data. However, the creation of circular glyphs remains a difficult task due to the demand for professional design skills and laborious design processes.  This paper presents an interactive authoring tool called GlyphCreator to support the example-based generation of circular glyphs. Given an example circular glyph and multidimensional input data, GlyphCreator can promptly generate a list of design candidates and supports interactive editing on the candidates to satisfy different design requirements. To develop GlyphCreator, we first derive a design space of circular glyphs from summarizing the relation between different visual elements. With this design space, we build a circular glyph dataset and develop a deep learning model for glyph parsing. The model is able to deconstruct a circular glyph bitmap into a series of visual elements.  Next, we propose an interface with effective interactions to help users bind the input data attributes to visual elements and customize visual styles. We evaluate the parsing model through a quantitative experiment and demonstrate the use of GlyphCreator through a usage scenario. The effectiveness of GlyphCreator is confirmed through user interviews.","Glyph-based visualization, machine learning, automatic visualization.",Lu,Ying,Tan,Tang,Yuzhe,Luo,Lvkesheng,Shen,Xiao,Xie,Lingyun,Yu,Yingcai,Wu,,,,,,,,,,,,,Lu Ying: Zhejiang University; Tan Tang: Zhejiang University; Yuzhe Luo: Zhejiang University; Lvkesheng Shen: Zhejiang University; Xiao Xie: Zhejiang University; Lingyun Yu: Xi'an Jiaotong-Liverpool University; Yingcai Wu: Zhejiang University,tangtan@zju.edu.cn; yzluo@zju.edu.cn; fantast0416@gmail.com; xxie@zju.edu.cn; lingyun.yu@xjtlu.edu.cn; ycwu@zju.edu.cn
Representations & Interaction,1600,Interactive Data Comics,"This paper investigates how to make data comics interactive. Data comics are an effective and versatile means for visual communication, leveraging the power of sequential narration and combined textual and visual content, while providing an overview of the storyline through panels assembled in expressive layouts. While a powerful static storytelling medium that works well on paper support, adding interactivity to data comics can enable non-linear storytelling, personalization, levels of details, explanations, and potentially enriched user experiences. This paper introduces a set of operations tailored to support data comics narrative goals that go beyond the traditional linear, immutable storyline curated by a story author. The goals and operations include adding and removing panels into pre-defined layouts to support branching, change of perspective, or access to detail-on-demand, as well as providing and modifying data, and interacting with data representation, to support personalization and reader-defined data focus. We propose a lightweight specification language, COMICSCRIPT, for designers to add such interactivity to static comics. To assess the viability of our authoring process, we recruited six professional illustrators, designers and data comics enthusiasts and asked them to craft an interactive comic, allowing us to understand authoring workflow and potential of our approach. We present examples of interactive comics in a gallery. This initial step towards understanding the design space of interactive comics can inform the design of creation tools and experiences for interactive storytelling.","Data comics, Non-linear narrative, interactive storytelling",Zezhong,Wang,Hugo,Romat,Fanny,Chevalier,Nathalie,Henry Riche,Dave,Murray-Rust,Benjamin,Bach,,,,,,,,,,,,,,,Zezhong Wang: University of Edinburgh ; Hugo Romat: ETH Zurich; Fanny Chevalier: University of Toronto; Nathalie Henry Riche: Microsoft Research; Dave Murray-Rust: TU Delft; Benjamin Bach: University of Edinburgh,hugo.romat@gmail.com; fanny@dgp.toronto.edu; nath@microsoft.com; d.s.murray-rust@tudelft.nl; bbach@inf.ed.ac.uk
Analytics & Decisions,1607,Real-Time Visual Analysis of High-Volume Social Media Posts,"Breaking news and first-hand reports often trend on social media platforms before traditional news outlets cover them. The real-time analysis of posts on such platforms can reveal valuable and timely insights for journalists, politicians, business analysts, and first responders, but the high number and diversity of new posts pose a challenge. In this work, we present an interactive system that enables the visual analysis of streaming social media data on a large scale in real-time. We propose an efficient and explainable dynamic clustering algorithm that powers a continuously updated visualization of the current thematic landscape as well as detailed visual summaries of specific topics of interest. Our parallel clustering strategy provides an adaptive stream with a digestible but diverse selection of recent posts related to relevant topics. We also integrate familiar visual metaphors that are highly interlinked for enabling both explorative and more focused monitoring tasks. Analysts can gradually increase the resolution to dive deeper into particular topics. In contrast to previous work, our system also works with non-geolocated posts and avoids extensive preprocessing such as detecting events. We evaluated our dynamic clustering algorithm and discuss several use cases that show the utility of our system.","Social media analysis, dynamic clustering, streaming data",Johannes,Knittel,Steffen,Koch,Tan,Tang,Wei,Chen,Yingcai,Wu,Shixia,Liu,Thomas,Ertl,,,,,,,,,,,,,Johannes Knittel: University of Stuttgart; Steffen Koch: University of Stuttgart; Tan Tang: Zhejiang University; Wei Chen: Zhejiang University; Yingcai Wu: Zhejiang University; Shixia Liu: Tsinghua University; Thomas Ertl: University of Stuttgart,steffen.koch@vis.uni-stuttgart.de; tangtan@zju.edu.cn; chenvis@zju.edu.cn; ycwu@zju.edu.cn; shixia@tsinghua.edu.cn; thomas.ertl@vis.uni-stuttgart.de
Analytics & Decisions,1621,Human-in-the-loop Extraction of Interpretable Concepts in Deep Learning Models,"The interpretation of deep neural networks (DNNs) has become a key topic as more people apply them to solve various problems and making critical decisions. Recently, concept-based explanation has become a popular approach for post-hoc interpretation of DNNs. Instead of focusing on a single data sample to obtain local interpretation such as saliency maps, concept-based explanation provides a global interpretation of model predictions by analyzing how visual concepts affects model decision. For example, how the presence of shadow affects an object detection model. However, identifying human-friendly visual concepts that affect model decisions is a challenging task that can not be easily addressed with automatic approaches. In this paper, we present a novel human-in-the-loop visual analytics framework to generate user-defined concepts for model interpretation and diagnostics. The core of our approach is the use of active learning, where we integrate human knowledge and feedback to train a concept extractor in each stage. We crop or segment the original images into small image patches, extract the latent presentations from the hidden layer of the task model, select image patches sharing a common concept, and train a shallow net on top of the latent representation to collect image patches containing the visual concept. We combine these processes into an interactive system, ConceptExtract. Through two case studies, we show how our approach helps analyze model behavior and extract human-friendly concepts for different machine learning tasks and datasets and how to use these concepts to understand the predictions, compare model performance and make suggestions for model refinement. Quantitative experiments show that our active learning approach can accurately extract meaningful visual concepts. More importantly, by identifying visual concepts that negatively affect model performance, we develop the corresponding data augmentation strategy that consistently improves model performance.","Visual Data Exploration, Deep Neural Network, Model Interpretation, Explainable AI",Zhenge,Zhao,Panpan,Xu,Carlos,Scheidegger,Liu,Ren,,,,,,,,,,,,,,,,,,,Zhenge Zhao: University of Arizona; Panpan Xu: Bosch Research; Carlos Scheidegger: University of Arizona; Liu Ren: Robert Bosch Research,xpp2007@gmail.com; cscheid@email.arizona.edu; liu.ren@us.bosch.com
Theoretical & Empirical,1633,Modeling Just Noticeable Differences in Charts,"One of the fundamental tasks in visualization is to compare two or more visual elements. However, it is often difficult to visually differentiate graphical elements encoding a small difference in value, such as the heights of similar bars in bar chart or angles of similar sections in pie chart. Perceptual laws can be used in order to model when and how we perceive this difference. In this work, we model the perception of Just Noticeable Differences (JNDs), the minimum difference in visual attributes that allow faithfully comparing similar elements, in charts. Specifically, we explore the relation between JNDs and two major visual variables: the intensity of visual elements and the distance between them, and study it in three charts: bar chart, pie chart and bubble chart. Through an empirical study, we identify main effects on JND for distance in bar charts, intensity in pie charts, and both distance and intensity in bubble charts. By fitting a linear mixed effects model, we model JND and find that JND grows as the exponential function of variables. We highlight several usage scenarios that make use of the JND modeling in which elements below the fitted JND are detected and enhanced with secondary visual cues for better discrimination.","Visual perception, Charts, Just noticeable difference, Modeling.",Min,Lu,Joel,Lanir,Chufeng,Wang,Yucong,Yao,Wen,Zhang,Oliver,Deussen,Hui,Huang,,,,,,,,,,,,,Min Lu: Shenzhen University; Joel Lanir: The University of Haifa; Chufeng Wang: Shenzhen University; Yucong Yao: College of Computer Science and Software Engineering; Wen Zhang: College of Computer Science and Software Engineering; Oliver Deussen: University of Konstanz; Hui Huang: Shenzhen University,ylanir@is.haifa.ac.il; chufengwang96@gmail.com; yyc173966019@gmail.com; zhangwen.thu@gmail.com; oliver.deussen@uni-konstanz.de; hhzhiyan@gmail.com
Representations & Interaction,1637,A Mixed-Initiative Approach to Reusing Infographic Charts,"Infographic bar charts have been widely adopted for communicating numerical information because of their attractiveness and memorability. However, these infographics are often created manually with general tools, such as PowerPoint and Adobe Illustrator, and merely composed of primitive visual elements, such as text blocks and shapes. With the absence of chart models, updating or reusing these infographics requires tedious and error-prone manual edits. In this paper, we propose a mixed-initiative approach to mitigate this pain point. On one hand, machines are adopted to perform precise and trivial operations, such as mapping numerical values to shape attributes and aligning shapes. On the other hand, we rely on humans to perform subjective and creative tasks, such as changing embellishments or approving the edits made by machines. We encapsulate our technique in a PowerPoint add-in prototype and demonstrate the effectiveness by applying our technique on a diverse set of infographic bar chart examples.","Infographics, Reusable templates, Graphic design, Automatic visualization.",Weiwei,Cui,Jinpeng,Wang,He,Huang,Yun,Wang,Chin-Yew,Lin,Haidong,Zhang,Dongmei,Zhang,,,,,,,,,,,,,Weiwei Cui: Microsoft Research Asia; Jinpeng Wang: Meituan; He Huang: Microsoft Research Asia; Yun Wang: Microsoft Research Asia; Chin-Yew Lin: Microsoft Research Asia; Haidong Zhang: Microsoft Research Asia; Dongmei Zhang: Microsoft Research Asia,wjppku@gmail.com; rayhuang@microsoft.com; wangyun@microsoft.com; cyl@microsoft.com; haizhang@microsoft.com; dongmeiz@microsoft.com
Systems & Rendering,1663,STRATISFIMAL LAYOUT: A modular optimization model for laying out layered node-link network visualizations,"Node-link visualizations are a familiar and powerful tool for displaying the relationships in a network. The readability of these visualizations highly depends on the spatial layout used for the nodes. In this paper, we focus on computing layered layouts, in which nodes are aligned on a set of parallel axes to better expose hierarchical or sequential relationships. Heuristic-based layouts are widely used as they scale well to larger networks and usually create readable, albeit sub-optimal, visualizations. We instead use a layout optimization model that prioritizes optimality (as compared to scalability) because an optimal solution not only represents the best attainable result, but can also serve as a baseline to evaluate the effectiveness of layout heuristics. We take an important step towards powerful and flexible network visualization by proposing Stratisfimal Layout, a modular integer-linear-programming formulation that can consider several important readability criteria simultaneously: crossing reduction, edge bendiness, and nested and multi-layer groups. The layout can be adapted to diverse use cases through its modularity. Individual features can be enabled and customized depending on the application. We provide open-source and documented implementations of the layout, both for web-based and desktop visualizations. As a proof-of-concept, we apply it to the problem of visualizing complicated SQL queries, which have features that, to the best of our knowledge, cannot be addressed by existing layout optimization models. We also include a benchmark network generator and the results of an empirical evaluation to assess the performance trade-offs of our design choices. A full version of this paper with all appendices, data, and source code is available at https://osf.io/3vqms with live examples at https://visdunneright.github.io/stratisfimal/.","Layered node-link visualization, integer linear programming, crossing reduction, bendiness reduction, nested groups",Sara,Di Bartolomeo,Mirek,Riedewald,Wolfgang,Gatterbauer,Cody,Dunne,,,,,,,,,,,,,,,,,,,Sara Di Bartolomeo: Northeastern University; Mirek Riedewald: Northeastern University; Wolfgang Gatterbauer: Northeastern University; Cody Dunne: Northeastern University,m.riedewald@northeastern.edu; w.gatterbauer@northeastern.edu; c.dunne@northeastern.edu
Applications,1681,Towards replacing physical testing of granular materials with a Topology-based Model,"In the study of packed granular materials, the performance of a sample (e.g., the detonation of a high-energy explosive) often correlates to measurements of a fluid flowing through it. The “effective surface area,” the surface area accessible to the airflow, is typically measured using a permeametry apparatus that relates the flow conductance to the permeable surface area via the Carman-Kozeny equation. This equation allows calculating the flow rate of a fluid flowing through the granules packed in the sample for a given pressure drop. However, Carman-Kozeny makes inherent assumptions about tunnel shapes and flow paths that may not accurately hold in situations where the particles possess a wide distribution in shapes, sizes, and aspect ratios, as is true with many powdered systems of technological and commercial interest. To address this challenge, we replicate these measurements virtually on micro-CT images of the powdered material, introducing a new Pore Network Model (PNM) based on the skeleton of the Morse-Smale complex. Pores are identified as basins of the complex, their incidence encodes adjacency, and the conductivity of the capillary between them computed from the cross-section at their interface. We build and solve a resistive network to compute an approximate laminar fluid flow through the pore structure. We provide two means of estimating flow-permeable surface area: (i) by direct computation of conductivity, and (ii) by identifying dead-ends in the flow coupled with isosurface extraction and the application of the Carman-Kozeny equation, with the aim of establishing consistency over a range of particle shapes, sizes, porosity levels, and void distribution patterns.","Physical and Environmental Sciences, Computational Topology-based Techniques, Data Abstractions and Types, Scalar Field Data",Aniketh,Venkat,Attila,Gyulassy,Graham,Kosiba,Amitesh,Maiti,Henry,Reinstein,Richard,Gee,Peer-Timo,Bremer,Valerio,Pascucci,,,,,,,,,,,Aniketh Venkat: Scientific Computing and Imaging Institute; Attila Gyulassy: Scientific Computing and Imaging Institute; Graham Kosiba: Lawrence Livermore National Laboratory; Amitesh Maiti: Lawrence Livermore National Laboratory; Henry Reinstein: Lawrence Livermore National Laboratory; Richard Gee: Lawrence Livermore National Laboratory; Peer-Timo Bremer: Lawrence Livermore National Laboratory; Valerio Pascucci: Scientific Computing and Imaging Institute,jediati@sci.utah.edu; kosiba1@llnl.gov; maiti2@llnl.gov; reinstein2@llnl.gov; gee10@llnl.gov; bremer5@llnl.gov; pascucci@sci.utah.edu
Theoretical & Empirical,1683,Understanding Data Visualization Design Practice,"Professional roles for data visualization designers are growing in popularity, and interest in relationships between the academic research and professional practice communities is gaining traction. However, despite the potential for knowledge sharing between these communities, we have little understanding of the ways in which practitioners design in real-world, professional settings. Inquiry in numerous design disciplines indicates that practitioners approach complex situations in ways that are fundamentally different from those of researchers. In this work, I take a practice-led approach to understanding design practice on its own terms. Twenty data visualization practitioners were interviewed and asked about their design process, including the steps they take, how they make decisions, and the methods they use. Findings suggest that practitioners do not follow highly systematic processes, but instead rely on situated forms of knowing and acting in which they draw from precedent and use methods and principles that are determined appropriate in the moment. These findings have implications for how visualization researchers understand and engage with practitioners, and how educators approach the training of future data visualization designers.","Design practice, data visualization, design methods, design process, research-practice relationships",Paul,Parsons,,,,,,,,,,,,,,,,,,,,,,,,,Paul Parsons: Purdue University,
Representations & Interaction,1685,Automatic Polygon Layout for Primal-Dual Visualization of Hypergraphs,"N-ary relationships, which relate N entities where N is not necessarily two, can be visually represented as polygons whose vertices are the entities of the relationships. Manually generating a high-quality layout using this representation is labor-intensive. In this paper, we provide an automatic polygon layout generation algorithm for the visualization of N-ary relationships. At the core of our algorithm is a set of objective functions motivated by a number of design principles that we have identified. These objective functions are then used in an optimization framework that we develop to achieve high-quality layouts. Recognizing the duality between entities and relationships in the data, we provide a second visualization in which the roles of entities and relationships in the original data are reversed. This can lead to additional insight about the data. Furthermore, we enhance our framework for a joint optimization on the primal layout (original data) and the dual layout (where the roles of entities and relationships are reversed). This allows users to inspect their data using two complementary views. We apply our visualization approach to a number of datasets that include co-authorship data and social contact pattern data.","Hypergraphs, hypergraph visualization, N-ary relationships, optimization, polygon layout, duality, primal-dual visualization",Botong,Qu,Eugene,Zhang,Yue,Zhang,,,,,,,,,,,,,,,,,,,,,Botong Qu: Oregon State University; Eugene Zhang: Oregon State University; Yue Zhang: Oregon State University,qub@oregonstate.edu; zhangyue@oregonstate.edu
Theoretical & Empirical,1696,Examining Effort in 1D Uncertainty Communication Using Individual Differences in Working Memory and NASA-TLX,"As uncertainty visualizations for general audiences become increasingly common, designers must understand the full impact of uncertainty communication techniques on viewers' decision processes. Prior work demonstrates mixed performance outcomes with respect to how individuals make decisions using various visual and textual depictions of uncertainty. Part of the inconsistency across findings may be due to an over-reliance on task accuracy, which cannot, on its own, provide a comprehensive understanding of how uncertainty visualization techniques support reasoning processes. In this work, we advance the debate surrounding the efficacy of modern 1D uncertainty visualizations by conducting converging quantitative and qualitative analyses of both the effort and strategies used by individuals when provided with quantile dotplots, density plots, interval plots, mean plots, and textual descriptions of uncertainty. We utilize two approaches for examining effort across uncertainty communication techniques: a measure of individual differences in working-memory capacity known as an operation span (OSPAN) task  and self-reports of perceived workload via the NASA-TLX. The results reveal that both visualization methods and working-memory capacity impact participants' decisions. Specifically, quantile dotplots and density plots (i.e., distributional annotations) result in more accurate judgments than interval plots, textual descriptions of uncertainty, and mean plots (i.e., summary annotations). Additionally, participants' open-ended responses suggest that individuals viewing distributional annotations are more likely to employ a strategy that explicitly incorporates uncertainty into their judgments than those viewing summary annotations. When comparing quantile dotplots to density plots, this work finds that both methods are equally effective for low-working-memory individuals. However, for individuals with high-working-memory capacity, quantile dotplots evoke more accurate responses with less perceived effort. Given these results, we advocate for the inclusion of converging behavioral and subjective workload metrics in addition to accuracy performance to further disambiguate meaningful differences among visualization techniques.","Uncertainty Visualization, Working Memory, Individual Differences, Online OSPAN, Effort, Workload, NASA-TLX",Spencer,Castro,Helia,Hosseinpour,P. Samuel,Quinan,Lace,Padilla,,,,,,,,,,,,,,,,,,,Spencer C. Castro: University of California Merced; Helia Hosseinpour: University of California Merced; P. Samuel Quinan: University of Utah; Lace Padilla: UC Merced,scastro39@ucmerced.edu; hhosseinpour@ucmerced.edu; psq@cs.utah.edu
Theoretical & Empirical,1730,The Weighted Average Illusion: Biases in Perceived Mean Position in Scatterplots,"Scatterplots can encode a third dimension by using additional channels like size or color (e.g. bubble charts). We explore a potential misinterpretation of trivariate scatterplots, which we call the weighted average illusion, where locations of larger and darker points are given more weight toward x- and y-mean estimates. This systematic bias is sensitive to a designer’s choice of size or lightness ranges mapped onto the data. In this paper, we quantify this bias against varying size/lightness ranges and data correlations. We discuss possible explanations for its cause by measuring attention given to individual data points using a vision science technique called the centroid method. Our work illustrates how ensemble processing mechanisms and mental shortcuts can significantly distort visual summaries of data, and can lead to misjudgments like the demonstrated weighted average illusion.","Human-Subjects Quantitative Studies, Perception & Cognition, Scatterplots, Feature-Based Attention, Bias",Matt-Ian,Hong,Jessica,Witt,Danielle,Szafir,,,,,,,,,,,,,,,,,,,,,Matt-Ian Hong: University of Colorado Boulder; Jessica Witt: Colorado State University; Danielle Albers Szafir: University of Colorado Boulder,jessica.witt@colostate.edu; danielle.szafir@colorado.edu